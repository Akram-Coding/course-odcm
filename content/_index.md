---
title: Introduction
type: docs
---

# Online Data Collection and Management (oDCM)

**Use web scraping and APIs to mine the web**

<!--, and database management-->

_Tilburg University, Block 3, 2020/2021 (February - April 2021)_

_Instructor: [dr. Hannes Datta](https://hannesdatta.com)_


## Learn how to mine the social web

Welcome to the course website of ODCM. This course teaches you the nuts and bolts about web scraping and application protocol interfaces (API). Unlike most of the courses you find online, this course not only teaches you about the technicalities of using scraping and APIs, but also introduces a comprehensive framework that helps you to "think" about web scraping - specifically with regard to how to use scraping for conducting academic marketing research.

## This website

This website is the backbone of the course, and features two main sections.

- The __course__ section holds a list of (weekly) [modules](docs/course/modules) and prerecorded lectures to watch. Even if you're not enrolled, you can watch these clips, but interaction with the course instructor is restricted to enrolled students only.

- The [__tutorial__](docs/tutorials) section offers a list of self-guided Jupyter Notebooks that teach you the *basics* of conducting web scraping and APIs.

- Finally, the __building block__ section offers a collection of code snippets in Python that you can use to build your own scrapers and API clients.

## Wanna enroll, or learn more about grading in this course?

Then head over to the [course syllabus](docs/course/syllabus).

<!--
## Glossary search

Already know what you're looking for? Search the __Glossary__ here.



Comments Roy:
- voorkennis eigenlijk verplicht

QUESTIONS SUSAN:
- dprep eerst laten lopen, dan pas web scraping
- niveau toetsen met python; entry exam ("encore")
- voorgangstoets

- duidelijk maken dat het geen peer review is!


- no need to prep each and every "deep" level

SESSIONS
++++++++

1) open session + #1 website exploration

2) website pitches from teams + advice on what could be interesting research settings/questions, or how data could be linked to other sources

-- SELF STUDY: prototype scraping

3) #2 Prototype: proof of concept laten zien
+ LECTURE: deployment

-- SCRAPER #3 deployment, databases [...]

4) Feedback

5) SESSION: #4 Data sharing, documentation

6) Poster session w/ powerpoint/ "verhaal" maken

-->
