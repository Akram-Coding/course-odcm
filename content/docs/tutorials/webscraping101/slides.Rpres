oDCM - Web Scraping 101 (Tutorial)
========================================================
author: Hannes Datta
date:
autosize: true

<style>
.small-code pre code {
  font-size: 1em;
}
</style>

<!--#

https://support.rstudio.com/hc/en-us/articles/200486468
-->

```{r setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(reticulate)
py_install("requests")
py_install("bs4")
```

Welcome to oDCM!
========================================================

We're about to start with __today's tutorial ("web scraping 101")__.

- If you haven't done so, open https://odcm.hannesdatta.com/docs/tutorials/webdata-101/
- Recap coaching session for team activity #1
  - explore broadly! ("universe discovery!")
  - compare sources thoroughly 
- Prepping for next coaching
   - get started soon w/ prototyping!
  
- Login at [http://pulse.tilburg-digital.com]() to explore this week's to do's

Agenda
========================================================

- In-class
  - Go through in-class tutorial ("web scraping 101")
  - Selection of exercises
  - Will spend some time on "Fields of Gold" as well
  - Will use different sites (e.g., Twitch)
- After class
  - Complete exercises yourselves

Making a connection with a site
=========
incremental: true

- So far, we have done this
  - `requests` (to get) --> `beautifulsoup` (to extract information, "parse")
  
- But... what about dynamic websites?
  - Run the snippet below and open `amazon.html`  
```{python, eval=FALSE}
import requests
header = 
f = open('amazon.html', 'w', encoding = 'utf-8')
f.write(requests.get('https://amazon.com', headers =  {'User-agent': 'Mozilla/5.0'}).text)
f.close()
```
  - Some sites block requests from the get-go, even w/ headers.

Alternative ways to make connections
========

- Selenium actually __opens__ a browser, and in so doing simulates browsing behavior.
- Try this:
```{python, eval=FALSE}
!pip install webdriver_manager
!pip install selenium

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

# Opening the site
driver = webdriver.Chrome(ChromeDriverManager().install())

url = "https://amazon.com/"
driver.get(url)
```

- See your browser?
- Beware of rerunning code - a new instance will run

Continuing with beautifulsoup
=========

```{python, eval=FALSE}
from bs4 import BeautifulSoup
soup = BeautifulSoup(driver.page_source)

for el in soup.find_all(class_ = 'a-section'):
    title = el.find('h2')
    if title is not None: print(title.text)
```

Do: Twitch.tv
=====

1. Use selenium to open `twitch.tv`

```{python, eval=FALSE}
import time
url = "https://twitch.tv/"
driver.get(url)
time.sleep(3)
```

__Tip: Use the code snippet from above first to open the browser window!__.

2. Extend code to be able to use BeautifulSoup, and find all links (tag is `a`). Recall: `soup.find_all()`

Finding more specific links
===========

- Suppose we only want streams, let's check out which additional attribute to search for.

```{python, eval = FALSE}

streams = soup.find_all('a', {'data-test-selector':"TitleAndChannel"})

```

__DO:__

- Write some code to show all the stream names!


Framework
=======

![](https://journals.sagepub.com/na101/home/literatum/publisher/sage/journals/content/jmxa/2022/jmxa_86_5/00222429221100750/20220801/images/large/10.1177_00222429221100750-fig2.jpeg)

Today: zooming in more on __collection design__

Stage 1: Which information to extract
========

- Challenges in Table 3 (#2.1) in tiu.nu/scraping/Fields of Gold.
  - Validity
  - Legal/Ethical
  - Technical
  
__Do:__

1. Which information would you be interested?
2. Has all of the information always been available? Check archive.org!
3. Write some code to capture information of interest
4. Wrap code in a function to parse information of interest, write to dictionary

Stage 2: For which sample?
=======

- Challenges in Table 3 (#2.2) in tiu.nu/scraping/Fields of Gold.

__Do:__ What potential sampling frames could you come up with? "How to start your data collection"?

- Let's extract list of currently running shows, using snippet from above. Store URL of stream in dictionary.

Stage 3: At which frequency
=======

Stage 4: How to process data during collection
==========

- let's retain raw data
- let's parse data on the fly

Next steps
===========

