{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API 101 (oDCM)\n",
    "\n",
    "*Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce pretium risus at ultricies egestas. Vivamus sit amet arcu sem. In hac habitasse platea dictumst. Nulla pharetra vitae mauris sed mollis. Pellentesque placerat mauris dui, in venenatis nisl posuere ac. Nunc vitae tincidunt risus, ut pellentesque odio. Donec quam neque, iaculis id eros et, condimentum vulputate nulla. Nullam sed ligula leo.*\n",
    "\n",
    "--- \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Students will be able to: \n",
    "* Send HTTP requests to retrieve data from APIs\n",
    "* Iterate over multiple pages \n",
    "* Extract and store results of API request\n",
    "\n",
    "--- \n",
    "\n",
    "## Acknowledgements\n",
    "This course draws on online resources built by Adam Williamson, Brian Keegan, Colt Steele, David Amos, Hannah Cushman Garland, Kimberly Fessel, and Thomas Laetsch. \n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "## Contact\n",
    "For technical issues try to be as specific as possible (e.g., include screenshots, your notebook, errors) so that we can help you better.\n",
    "\n",
    "**WhatsApp**  \n",
    "+31 13 466 8938\n",
    "\n",
    "**Email**  \n",
    "odcm@uvt.nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XXX\n",
    "\n",
    "### 1.1 What is Reddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we already touched upon the Reddit API last time, we'll provide a more throrough description here as this entire tutorial is devoted to getting started with the API. Reddit is sometimes described as the *frontpage of the internet* since it gives you an up to date view on what's happening around the world. It's based on the principle that the community of around 1 billion users decides what is newsworthy and what's not through a voting system. You can think of Reddit upvotes as Facebook likes. Posts  are arranged based on the number of votes and those with many upvotes are featured on the homepage. The gray number next to each post represents the sum of votes (= upvotes - downvotes; 7013 in the figure below). \n",
    "\n",
    "<img src=\"images/reddit_science.png\" width=70% align=\"left\"  style=\"border: 1px solid black\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can post content in subreddits which are niche communities around a specific topic. There is a subreddit for almost everything, and they all start with `reddit.com/r/...`, for example, [askreddit](https://www.reddit.com/r/AskReddit), [aww](https://www.reddit.com/r/aww/), [gifs](https://www.reddit.com/r/gifs/), [showerthoughts](https://www.reddit.com/r/Showerthoughts), [lifehacks](https://www.reddit.com/r/lifehacks), [getmotivated](https://www.reddit.com/r/GetMotivated), [moviedetails](https://www.reddit.com/r/MovieDetails), [todayilearned](https://www.reddit.com/r/todayilearned/), or [foodporn](https://www.reddit.com/r/FoodPorn/). Subreddits are hosted by moderators and come with their own set of rules (e.g., links to papers you share in [`r/science`](https://www.reddit.com/r/science/) must be less than 6 months old). Other users can join a subreddit so that they receive updates about new posts and comments.\n",
    "\n",
    "<img src=\"images/reddit_moderators.png\" width=70% align=\"left\"  style=\"border: 1px solid black\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine who are the moderators? \n",
    "* When are moderators most active posting and commenting? \n",
    "\n",
    "* add `.json` (https://curl.trillworks.com)\n",
    "* request headers -> paste in cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {'authority': 'www.reddit.com', 'cache-control': 'max-age=0', 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'sec-fetch-site': 'same-origin', 'sec-fetch-mode': 'navigate', 'sec-fetch-user': '?1', 'sec-fetch-dest': 'document', 'accept-language': 'en-GB,en;q=0.9'}\n",
    "\n",
    "response = requests.get('https://www.reddit.com/r/marketing/about/moderators/.json', headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'dpatrick86',\n",
       "  'author_flair_text': None,\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1284657752.0,\n",
       "  'rel_id': 'rb_7n2fa',\n",
       "  'id': 't2_3c2ya',\n",
       "  'author_flair_css_class': None},\n",
       " {'name': 'v022450781',\n",
       "  'author_flair_text': '@valters',\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1304131436.0,\n",
       "  'rel_id': 'rb_epdsv',\n",
       "  'id': 't2_4zxlp',\n",
       "  'author_flair_css_class': 'fl-marketer'},\n",
       " {'name': 'r0nin',\n",
       "  'author_flair_text': None,\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1304616384.0,\n",
       "  'rel_id': 'rb_exhei',\n",
       "  'id': 't2_3f1dg',\n",
       "  'author_flair_css_class': None},\n",
       " {'name': 'Gustomaximus',\n",
       "  'author_flair_text': 'Professional',\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1304616402.0,\n",
       "  'rel_id': 'rb_exhf2',\n",
       "  'id': 't2_43san',\n",
       "  'author_flair_css_class': 'fl-professional'},\n",
       " {'name': 'everythingswan',\n",
       "  'author_flair_text': None,\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1329421838.0,\n",
       "  'rel_id': 'rb_ym8h7',\n",
       "  'id': 't2_4myk4',\n",
       "  'author_flair_css_class': None},\n",
       " {'name': 'sixwaystop313',\n",
       "  'author_flair_text': '@stevestgermain',\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1332192698.0,\n",
       "  'rel_id': 'rb_12a0w9',\n",
       "  'id': 't2_3pmgd',\n",
       "  'author_flair_css_class': 'instagram'},\n",
       " {'name': 'shampine',\n",
       "  'author_flair_text': '@patrickshampine',\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1378927428.0,\n",
       "  'rel_id': 'rb_3ww0bm',\n",
       "  'id': 't2_8apro',\n",
       "  'author_flair_css_class': 'instagram'},\n",
       " {'name': 'JonODonovan',\n",
       "  'author_flair_text': 'Marketing is fun',\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1431348542.0,\n",
       "  'rel_id': 'rb_adarll',\n",
       "  'id': 't2_gqh8s',\n",
       "  'author_flair_css_class': 'fl-marketer'},\n",
       " {'name': 'AutoModerator',\n",
       "  'author_flair_text': None,\n",
       "  'mod_permissions': ['posts', 'access', 'flair'],\n",
       "  'date': 1489504326.0,\n",
       "  'rel_id': 'rb_mxt9ff',\n",
       "  'id': 't2_6l4z3',\n",
       "  'author_flair_css_class': None},\n",
       " {'name': 'AptSeagull',\n",
       "  'author_flair_text': None,\n",
       "  'mod_permissions': ['all'],\n",
       "  'date': 1551213226.0,\n",
       "  'rel_id': 'rb_174h7m4',\n",
       "  'id': 't2_2ysubsuk',\n",
       "  'author_flair_css_class': None}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = response.json()\n",
    "json_response['data']['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpatrick86\n",
      "v022450781\n",
      "r0nin\n",
      "Gustomaximus\n",
      "everythingswan\n",
      "sixwaystop313\n",
      "shampine\n",
      "JonODonovan\n",
      "AutoModerator\n",
      "AptSeagull\n"
     ]
    }
   ],
   "source": [
    "# create a list of moderators\n",
    "[item['name'] for item in json_response['data']['children']]\n",
    "\n",
    "for item in json_response['data']['children']: \n",
    "    print(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpatrick86\n",
      "v022450781\n",
      "r0nin\n",
      "Gustomaximus\n",
      "everythingswan\n",
      "sixwaystop313\n",
      "shampine\n",
      "JonODonovan\n",
      "AptSeagull\n"
     ]
    }
   ],
   "source": [
    "# ignore the AutoModerator\n",
    "for item in json_response['data']['children']: \n",
    "    if item['name'] != 'AutoModerator':\n",
    "        print(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dpatrick86',\n",
       " 'v022450781',\n",
       " 'r0nin',\n",
       " 'Gustomaximus',\n",
       " 'everythingswan',\n",
       " 'sixwaystop313',\n",
       " 'shampine',\n",
       " 'JonODonovan',\n",
       " 'AptSeagull']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get the moderators from any subreddit\n",
    "def get_mods(subreddit):\n",
    "    response = response = requests.get(f'https://www.reddit.com/r/{subreddit}/about/moderators/.json', headers=headers)\n",
    "    json_response = response.json()\n",
    "    mods = [item['name'] for item in json_response['data']['children'] if item['name'] != 'AutoModerator']\n",
    "    return mods\n",
    "    \n",
    "get_mods('marketing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subreddit': 'marketing', 'mod': 'dpatrick86'},\n",
       " {'subreddit': 'marketing', 'mod': 'v022450781'},\n",
       " {'subreddit': 'marketing', 'mod': 'r0nin'},\n",
       " {'subreddit': 'marketing', 'mod': 'Gustomaximus'},\n",
       " {'subreddit': 'marketing', 'mod': 'everythingswan'},\n",
       " {'subreddit': 'marketing', 'mod': 'sixwaystop313'},\n",
       " {'subreddit': 'marketing', 'mod': 'shampine'},\n",
       " {'subreddit': 'marketing', 'mod': 'JonODonovan'},\n",
       " {'subreddit': 'marketing', 'mod': 'AptSeagull'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return both subreddit and moderators and store in dictionary\n",
    "# function to get the moderators from any subreddit\n",
    "def get_mods(subreddit):\n",
    "    response = response = requests.get(f'https://www.reddit.com/r/{subreddit}/about/moderators/.json', headers=headers)\n",
    "    json_response = response.json()\n",
    "    mods = [{'subreddit': subreddit, 'mod': item['name']} for item in json_response['data']['children'] if item['name'] != 'AutoModerator']\n",
    "    return mods\n",
    "    \n",
    "get_mods('marketing')\n",
    "\n",
    "# kan niet gewoon subreddit: name doen want een key moet altijd uniek zijn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Humans do not really change the parameters in the search bar (but use buttons and sliders on the page for that)\n",
    "* For each joke we have an id and the joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "# rather than hardcoding it like this\n",
    "response = requests.get(\n",
    "    \"http://www.example.com?key1=value1&key2=value2\"\n",
    ")\n",
    "\n",
    "# this is the preferred way \n",
    "response = requests.get(\n",
    "    \"http://www.example.com\",\n",
    "    params={\n",
    "        \"key1\": \"value1\",\n",
    "        \"key2\": \"value2\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation: https://icanhazdadjoke.com/api\n",
    "# page = which page of the results to fetch (default: 1)\n",
    "# limit = number of results per page (default: 20) (max:30)\n",
    "# term = search term to use (default: list all jokes)\n",
    "url = \"https://icanhazdadjoke.com/search\"\n",
    "response = requests.get(url, \n",
    "                        headers={\"Accept\": \"application/json\"},\n",
    "                        params={\"term\": \"cat\",\n",
    "                                \"page\": 2,\n",
    "                                \"limit\": 1}\n",
    "                        \n",
    "                       )\n",
    "data = response.json() # similar to a Python dictionary\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API project\n",
    "* Print out a random joke according to user search query\n",
    "* If there are no jokes about -> appropriate message (\"Sorry, I don't have any jokes about X. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/kimfetti/Conferences/tree/master/PyCon_2020\n",
    "* https://www.youtube.com/watch?v=RUQWPJ1T6Zc&t=190s\n",
    "* https://github.com/hancush/web-scraping-with-python/blob/master/session/web-scraping-with-python.ipynb#HTML-basics\n",
    "* https://www.udemy.com/course/the-modern-python3-bootcamp/learn/lecture/7991196#overview\n",
    "* https://campus.datacamp.com/courses/web-scraping-with-python/introduction-to-html?ex=1\n",
    "* https://realpython.com/python-web-scraping-practical-introduction/\n",
    "* https://github.com/CU-ITSS/Web-Data-Scraping-S2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
