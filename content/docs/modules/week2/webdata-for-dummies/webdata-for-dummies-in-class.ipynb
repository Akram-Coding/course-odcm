{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web data for dummies (in-class)\n",
    "\n",
    "*The internet offers abundant possibilities to collect data for use in empirical research projects. This tutorial is a gentle introduction on how web scraping and APIs to collect such data in Python. Get inspired now!*\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completion of this tutorial, students will be able to:\n",
    "\n",
    "* Explain the differences between retrieving data from websites vs. APIs\n",
    "* Retrieve web data in Python using the `requests` library, and store retrieved data in HTML or JSON/TXT files for further inspection.\n",
    "* Use browser control tools (\"inspect\") to develop strategies how to select and capture information from websites (e.g., text, numbers, pictures, etc.)\n",
    "* Select elements from websites using BeautifulSoup (e.g., class names, attribute or tag names)\n",
    "* Select elements from JSON dictionaries obtained through APIs (attribute-value pairs)\n",
    "* Apply programming concepts (e.g., loops, functions) to the collection of web data, and convert dictionaries to JSON files.\n",
    "* Understand the difference between Jupyter Notebooks and “raw” Python files, and run collection via the command line/terminal\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Support Needed?</b> \n",
    "    For technical issues outside of scheduled classes, please check the <a href=\"https://odcm.hannesdatta.com/docs/course/support\" target=\"_blank\">support section</a> on the course website.\n",
    "</div>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Web Scraping\n",
    "\n",
    "### 1.1 What is web scraping?\n",
    "\n",
    "Say that you want to capture and analyze data from a website. Of course, you could simply copy-paste the data from each page. But, of course, this manually executed job would have severe limitations. What if the data on the page gets updated (i.e., would you have time available to copy-paste the new data, too)? Or what if there are simply so many pages that you can't possibly do it all by hand (i.e., thousands of product pages)? \n",
    "\n",
    "Web scraping can help you overcome these issues __by programmatically extracting data from the web__. Before we can extract/grab/capture/scrape information from a website, we need a bit of background on how websites work technically, so let's focus on that first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. How websites work\n",
    "\n",
    "#### Importance\n",
    "\n",
    "It's vital to take some time to get familiar with HTML - the primary programming language used when building websites. Once we're familiar with HTML (and the structure of websites), we can rapidly navigate complex websites to extract the information we're interested in (e.g., prices, names of product categories, ...). In other words: to reach our end goal, we do have to give you some technical details first.\n",
    "\n",
    "So, here we go: A web page consists of various text files, each one with its style, formatting, and syntax. These files each serve a specific purpose:\n",
    "\n",
    "- `.html` (HyperText Markup Language) files give structure to a page (e.g., where's the menu?, which content to show (e.g., text, tables)?)\n",
    "- `.css` (Cascading Style Sheet) files determine how the page looks (e.g., which color do headers have? what's the font used for text in a paragraph?)\n",
    "- `.js` (JavaScript) files add interactivity (e.g., button animations)\n",
    "\n",
    "#### Let's try it out\n",
    "Check out this simple [example](https://codepen.io/rcyou/pen/QEObEk/). The site shows the source code of a site (`.html`, `.css`, and `.js`) in an online editor, along with a rendered (\"viewable\") version of the site. Once you make changes to the code, the site gets automatically updated.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/codepen.png\" align=\"left\" width=60%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1 \n",
    "Just to get a feeling for how things work, let's make the following changes in the [CodePen snippet](https://codepen.io/rcyou/pen/QEObEk/): \n",
    "1. Change the text between the `<h1>` tags to `I am a purple of size 3em`. \n",
    "2. Change the `h1` font-size to `3em` and the color to purple (add `color: purple;` below `margin-bottom`).  \n",
    "3. Remove the JavaScript code. What happens now when you click the blue button?\n",
    "\n",
    "\n",
    "#### Solutions\n",
    "Clicking the button should no longer trigger the script to hide the paragraph text.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/purple_headline.png\" align=\"left\" width=60%/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Advancing HTML skills\n",
    "\n",
    "#### Importance\n",
    "\n",
    "Most HTML elements are represented by a pair of tags - an opening tag and a closing tag. \n",
    "\n",
    "For example, a table starts with `<table>` and ends with `</table>`. The first tag tells the browser: \"Hey! I got a table here! Render it as a table, so it displays nicely on the site.\" The closing tag (note the forward-slash!) tells the browser: \"Hey! I'm all done with that table, thanks.\" Inside the table are nested more HTML tags representing rows (`<tr>`) and cells (`<td>`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<html>\n",
    "    <table id=\"example-table\" class=\"striped-table\" style=\"width: 95%\">\n",
    "        <tr> <!-- Header row, starting with <tr> -->\n",
    "            <td>Column A</td> <!-- Columns, starting with <td> -->\n",
    "            <td>Column B</td>\n",
    "        </tr> <!-- observe that we always \"close a row\" to indicate we're done -->\n",
    "        <tr> <!-- Row 1 --->\n",
    "            <td>Row 1, Column A</td>\n",
    "            <td>Row 1, Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 2 --->\n",
    "            <td>Row 2, Column A</td>\n",
    "            <td>Row 2, Column B</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This what the rendered HTML table looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <table id=\"example-table\" class=\"striped-table\" style=\"width: 95%\">\n",
    "        <tr> <!-- Header -->\n",
    "            <td>Column A</td>\n",
    "            <td>Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 1 --->\n",
    "            <td>Row 1, Column A</td>\n",
    "            <td>Row 1, Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 2 --->\n",
    "            <td>Row 2, Column A</td>\n",
    "            <td>Row 2, Column B</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HTML elements can have any number of\n",
    "\n",
    "- __attributes__, such as IDs, which sometimes (but not always) *uniquely* identify elements\n",
    "\n",
    "```html\n",
    "<table id=\"example-table\">\n",
    "```\n",
    "\n",
    "- __classes__, which identify a *type* of an element (but barely uniquely identify a unique element -- i.e., they are mostly used more than once)\n",
    "\n",
    "```html\n",
    "<table class=\"striped-table\">\n",
    "```\n",
    "\n",
    "- and __styles__, which define how specific elements *appear* (e.g. the width of the table)\n",
    "\n",
    "```html\n",
    "<table style=\"width:95%;\">\n",
    "```\n",
    "\n",
    "As you may already have noticed, we use spaces (or tabs) to separate the elements from one another (the geeks among us will call this \"indentation\") to provide structure and improve readability. Yes, that's right. *Improve readability*.\n",
    "\n",
    "Code may look complex to read at first, but when you take a closer look at it, it boils down to simple English, following a particular structure (also known as syntax). For example, the `<table>` tag is placed farther to the right than the `<html>` tag indicates that the table is nested within the HTML block.\n",
    "\n",
    "This may be a lot to take in if you're entirely new to HTML, but don't worry, as the goal of this section is not to teach you how to code from scratch but rather to teach you what HTML is and why it is relevant for web scraping.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Why are attributes and classes important?</b> \n",
    "Recall that we use webscraping to \"capture\" content from websites. But - not all of the content will be relevant. We require attributes and classes to \"select\" content that we want to save. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's try it out__\n",
    "\n",
    "Double-click on the rendered table below to edit its HTML structure. Try to change some simple things, e.g., the text. Rerun the cell (Shift + Enter, or click the Run button in Juypyter Notebook). Watch your changes come alive!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2\n",
    "\n",
    "Please finish the exercises below. After each change, rerun the cell.\n",
    "\n",
    "1. Add another row in the table above to become a 2 (columns) x 4 (rows) table. That is 3 regular rows and 1 table header row.\n",
    "2. Fill the cells with the corresponding text labels (e.g., Row 3, Column A). \n",
    "3. Change the table width to `50%` so that the table becomes narrower.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Proceed in small steps!</b> \n",
    "Try not to make too many changes at once. Always proceed in small steps to see whether your code still works!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Make your changes here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <table id=\"example-table\" class=\"striped-table\" style=\"width: 95%\">\n",
    "        <tr> <!-- Header -->\n",
    "            <td>Column A</td>\n",
    "            <td>Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 1 --->\n",
    "            <td>Row 1, Column A</td>\n",
    "            <td>Row 1, Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 2 --->\n",
    "            <td>Row 2, Column A</td>\n",
    "            <td>Row 2, Column B</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**\n",
    "<html>\n",
    "    <table id=\"example-table\" class=\"striped-table\" style=\"width: 50%\">\n",
    "        <tr> <!-- Header -->\n",
    "            <td>Column A</td>\n",
    "            <td>Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 1 --->\n",
    "            <td>Row 1, Column A</td>\n",
    "            <td>Row 1, Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 2 --->\n",
    "            <td>Row 2, Column A</td>\n",
    "            <td>Row 2, Column B</td>\n",
    "        </tr>\n",
    "        <tr> <!-- Row 3 --->\n",
    "            <td>Row 3, Column A</td>\n",
    "            <td>Row 3, Column B</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 1.4 Finding content in a website's source code\n",
    "\n",
    "#### Importance\n",
    "\n",
    "Alright, we've now covered tables (`<table>`). However, there are hundreds of different tag words in HTML, and it's impossible to memorize all of them. That's why developers use a pretty handy tool to *inspect the source* of a website directly in the browser. From now onwards, we recommend you to use Chrome (in Safari and Firefox, things look slightly different, and we can't cover those, unfortunately.)\n",
    "\n",
    "Suppose you have identified an element you want to capture (e.g., a price or the name of a product). You can \"ask\" your browser for the specific HTML tag of that object (so it becomes easier to capture that element later). \n",
    "\n",
    "#### Let's try it out \n",
    "\n",
    "\n",
    "How does it work? Start by inspecting specific elements on the page by *right-clicking on the page* and selecting __\"Inspect\"__ from the context menu that pops up. Then, hover over elements in the \"Elements\" tab to highlight them on the page. This can be super helpful when you're trying to figure out how to (uniquely) identify the element you want to scrape.\n",
    "\n",
    "Check out the HTML structure of this fictitious [music streaming platform](https://music-to-scrape.org). The site displays the most frequently listened to songs, featured artists, and a selection of the platform's most recently active users. You can click through to subsections of the site, learning more about artists, songs, and users. Note that the data has been randomly generated, so the figures on your screen may deviate from the ones below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/music-to-scrape-inspect.png\" align=\"left\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the screenshot above, we've selected the artist \"Russell Malone,\" right-clicked on it, and chose \"Inspect.\" The same text is highlighted in blue in the HTML code below. \n",
    "\n",
    "__Try it out yourself!__\n",
    "\n",
    "The `<h2>` and `</h2>` tags surrounding the artist's name indicate that this text is a (sub)header on the web page. Move your pointer down to the line below (`<div class=\"about_artist\">`), and you'll see that on the top screen, it now highlights the artist's location and number of plays (rather than the name). This way, you can quickly investigate any webpage. \n",
    "\n",
    "__Also try this out...!__\n",
    "\n",
    "As we discussed earlier, tags can be nested within other tags. This also becomes clear from the screenshot below, in which the small gray triangles (▶) indicate that there is code hidden within these blocks. Click on them to expand the code, see what's inside, and click again to collapse them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/music-to-scrape-tags.png\" align=\"left\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3\n",
    "1. Use the inspect tool to find the HTML element that constitutes the table header \"**Top 10 songs of all time**\" at the bottom of [this page](https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B).\n",
    "2. Look up how many elements in that table start with a new row, using the HTML tag word `tr` (within the Inspector screen, use `Ctrl+F` on a PC or `⌘+F` on Mac to search)\n",
    "3. You can make local (only on your computer) changes to the web page by double-clicking in the inspector and swapping the code for something else (yes, you can overwrite what's already written there!). Change the name of the artist or the number of plays.\n",
    "4. After making the changes in 3.), refresh the page (reload it). What happens (and why)?\n",
    "\n",
    "*\"Faked\" location and plays.*\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/music-to-scrape-fake.png\" width=40% align=\"left\"  style=\"border: 1px solid black\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "1. The `<table>` (table header) tags with the class `top-songs`.\n",
    "2. At the time of writing, two elements point to rows (`tr`) - one being the header, another one being the actual data.\n",
    "3. See screenshot. \n",
    "4. Once you refresh the page, the original (unedited price and star rating) appears again.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Loading a website's source code into Python\n",
    "\n",
    "#### Importance\n",
    "\n",
    "Alright. Up to this moment, we've learned about HTML and fiddled around with a website's source code. But we finally want to understand how we can load a website's source code into Python.\n",
    "\n",
    "Rather than (manually) using the Inspector, we now automate these tasks using Python's `requests` library. Libraries are \"extensions\" to Python, but most of them are not loaded by default. So let's import the library using `import requests`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please (re)run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<!-- Head -->\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>We love being scraped | music-to-scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"https://unpkg.com/swiper/swiper-bundle.min.css\" />\n",
      "    <link href=\"https://fonts.googleapis.com/css?family=Rubik\" rel=\"stylesheet\">\n",
      "    <script src=\"https://kit.fontawesome.com/4e7776d591.js\" crossorigin=\"anonymous\"></script>\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/style.css\">\n",
      "    <script src=\"/static/js/cookies.js\"></script>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"cookie-banner\">\n",
      "        <p>This website uses <a href=\"/privacy_terms\">cookies</a> to improve your experience on our website.</p>\n",
      "        <button class=\"btn btn-primary mr-2\" id=\"accept-cookies\">Accept</button>\n",
      "        <button class=\"btn btn-secondary mr-2\" id=\"reject-cookies\">Deny</button>\n",
      "        <button class=\"btn btn-secondary\" id=\"cookie-preferences\" onclick=\"showCookiePreferences()\">Manage Consent</button>\n",
      "    </div>\n",
      "\n",
      "    <div id=\"cookie-preferences-popup\">\n",
      "        <h2>Manage Consent</h2>\n",
      "        <p>You have full control over your cookies at music-to-scrape.org:</p>\n",
      "        <ul>\n",
      "            <li>\n",
      "                <input type=\"checkbox\" id=\"analytics-cookie\">\n",
      "                <label for=\"analytics-cookie\"><strong>Google Analytics:</strong> This code manages the deployment of various marketing and analytics tags on the website.</label>\n",
      "            </li>\n",
      "        </ul>\n",
      "        <p>Want to know more? Check our <a href=\"/privacy_terms\">Privacy & Terms of Use</a></p>\n",
      "        <button class=\"btn btn-primary\" onclick=\"saveCookiePreferences()\">Save Consent</button>\n",
      "    </div>\n",
      "    \n",
      "    \n",
      "\n",
      "<!-- loaded -->\n",
      "\n",
      "<!-- Header -->\n",
      "<header>\n",
      "    <!-- Top Bar -->\n",
      "    <a href=\"about\"><div class=\"top-bar\">\n",
      "\t\t<p>We are a fictitious music streaming service without real data - use us to learn collecting data with web scraping and APIs.</p>\n",
      "\t</div></a>\n",
      "    <!-- End Top Bar -->\n",
      "\n",
      "    <!-- NavBar -->\n",
      "    <nav class=\"navbar navbar-expand-lg navbar-light bg-light\">\n",
      "        <a class=\"navbar-brand\" href=\"/\"><img src=\"/static/images/logo.png\" width=\"200\" height=\"27\" class=\"logo\"></a>\n",
      "        <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#navbarSupportedContent\"\n",
      "            aria-controls=\"navbarSupportedContent\" aria-expanded=\"false\" aria-label=\"Toggle navigation\">\n",
      "            <span class=\"navbar-toggler-icon\"></span>\n",
      "        </button>\n",
      "\n",
      "        <div class=\"collapse navbar-collapse\" id=\"navbarSupportedContent\">\n",
      "            <ul class=\"navbar-nav mr-auto align-content-center\" style=\"color: rgb(1,51,101)\">\n",
      "                <li class=\"nav-item active\" style=\"color: rgb(1,51,101)\">\n",
      "                    <a class=\"nav-link\" href=\"/\">Home <span class=\"sr-only\">(current)</span></a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                    <a class=\"nav-link\" href=\"/tutorial_scraping\">Learn how to scrape</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                    <a class=\"nav-link\" href=\"/tutorial_api\">Learn how to use API</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item dropdown\">\n",
      "                    <a class=\"nav-link dropdown-toggle\" href=\"#\" id=\"navbarDropdown\" role=\"button\"\n",
      "                        data-toggle=\"dropdown\" aria-haspopup=\"true\" aria-expanded=\"false\">\n",
      "                        More Resources\n",
      "                    </a>\n",
      "                    <div class=\"dropdown-menu\" aria-labelledby=\"navbarDropdown\">\n",
      "                        <a class=\"dropdown-item\" href=\"https://api.music-to-scrape.org/docs\">API documentation</a>\n",
      "                        <a class=\"dropdown-item\" href=\"/about\">About us</a>\n",
      "                        <!--<a class=\"dropdown-item\" href=\"#\">Another action</a>\n",
      "                        <div class=\"dropdown-divider\"></div>\n",
      "                        <a class=\"dropdown-item\" href=\"#\">Something else here</a>\n",
      "                        -->\n",
      "                    </div>\n",
      "                </li>\n",
      "            </ul>\n",
      "            <form action=\"/search\" class=\"form-inline my-2 my-lg-0\" method=\"get\">\n",
      "                <input class=\"form-control mr-sm-2\" name=\"query\" type=\"search\" placeholder=\"Search for artists, songs, and users\" aria-label=\"Search\" style=\"width:300px\">\n",
      "                <input type=\"hidden\" name=\"page\" value=\"\">\n",
      "                <button class=\"btn btn-outline-success my-2 my-sm-0\" type=\"submit\">Search</button>\n",
      "            </form>\n",
      "        </div>\n",
      "    </nav>\n",
      "    <!-- End navbar -->\n",
      "</header>\n",
      "\n",
      "\n",
      "\n",
      "<!-- Main Container-->\n",
      "<div class=\"container\">\n",
      "\n",
      "    <!-- Artist Info -->\n",
      "    <section>\n",
      "        <div class=\"row my-3\">\n",
      "            <div class=\"col-lg-4 album_single_img\">\n",
      "                <img src=\"https://images.unsplash.com/photo-1605722243979-fe0be8158232?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8Mnx8fGVufDB8fHx8&w=1000&q=80\"\n",
      "                    class=\"img-fluid\">\n",
      "            </div>\n",
      "            <div class=\"col-lg-8 album_single_text\">\n",
      "                <h2 class=\"artist_info_title\">Russell Malone</h2>\n",
      "                <div class=\"about_artist\">\n",
      "                    <h5>Location:</h5>\n",
      "                    <p>Albany GA</p>\n",
      "                    <h5>Number of plays:</h5>\n",
      "                    <p>10</p>\n",
      "                    <!--<h5>Number of Playlists:</h5>\n",
      "                    <p>24</p>-->\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "    </section>\n",
      "    <!-- End Artist Info -->\n",
      "\n",
      "    <!-- Tracks -->\n",
      "    <section></section>\n",
      "    <div class=\"row my-3\">\n",
      "        <div class=\"col-md-12\">\n",
      "            <h2>Top 10 Songs All Time</h2>\n",
      "            <div class=\"table-responsive\">\n",
      "                <table class=\"table table-striped\">\n",
      "                    <thead>\n",
      "                        <tr>\n",
      "                            <th>#</th>\n",
      "                            <th>Song Title</th>\n",
      "                            <!--<th>Artist</th>-->\n",
      "                            <th>Number of Plays</th>\n",
      "                        </tr>\n",
      "                    </thead>\n",
      "                    <tbody>\n",
      "                        \n",
      "\n",
      "                        <tr onclick=\"window.location.href = 'song?song-id=SOOYYGD12A8C131830';\">\n",
      "                            <td>1</td>\n",
      "                            <td>Sugar Buzz</td>\n",
      "                            <!--<td></td>-->\n",
      "                            <td>10</td>\n",
      "                        </tr>\n",
      "                        \n",
      "                    </tbody>\n",
      "                </table>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    </section>\n",
      "    <!-- End of Tracks-->\n",
      "\n",
      "</div>\n",
      "<!-- End Main Container-->\n",
      "\n",
      "\n",
      "\n",
      "<!-- Footer -->\n",
      "<footer>\n",
      "    <div class=\"container pt-5 border-bottom\">\n",
      "        <div class=\"row\">\n",
      "            <div class=\"col-md-3 col-sm-12 mb-3\">\n",
      "                <img src=\"/static/images/logo.png\" width=\"200\" height=\"30\"\n",
      "                    class=\"logo_footer\"><br><br>\n",
      "                <p>We’re a fictitious music streaming service with a real website and API. Built for educational\n",
      "                    purposes, you can use us to learn web scraping! </p>\n",
      "            </div>\n",
      "            <div class=\"col-md-9 col-sm-12\">\n",
      "                \n",
      "                <div class=\"col-md-4 col-sm-6 col-6 p-0 mb-3 float-left\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">Learn how to scrape</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/tutorial_scraping\">Tutorial: How to scrape\n",
      "                                the site</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/tutorial_api\">Tutorial: Using the\n",
      "                                API</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"https://api.music-to-scrape.org/docs\">API Documentation</a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "\n",
      "                <div class=\"col-md-4 col-sm-6 col-6 p-0 float-left mb-3\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">About us</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/about\">Who we are</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/privacy_terms\">Privacy & Terms of Use</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a style=\"color: gray;cursor:pointer\" onclick=\"showCookiePreferences()\">Manage Cookies</a></li>\n",
      "                        <!--\n",
      "                            <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        -->\n",
      "                    </ul>\n",
      "                </div>\n",
      "                \n",
      "                \n",
      "            \n",
      "                <div class=\"col-md-3 col-sm-6 col-6 mb-3 p-0 float-left\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">Connect</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://www.linkedin.com/company/tilburgsciencehub\"><i class=\"fa fa-linkedin mr-1\"></i>\n",
      "                                LinkedIn</a>\n",
      "                        </li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://github.com/tilburgsciencehub/music-to-scrape\" target=\"_blank\"><i class=\"fa fa-github mr-1\"></i>\n",
      "                                GitHub</a>\n",
      "                        </li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://twitter.com/tilburgscience\" target=\"_blank\"><i class=\"fa fa-twitter mr-1\"></i>Twitter</a>\n",
      "                        </li>\n",
      "                        <!--<li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"\" target=\"_blank\"><i class=\"fa fa-youtube mr-1\"></i> YouTube</a>\n",
      "                        </li>\n",
      "                    -->\n",
      "                    </ul>\n",
      "                </div>\n",
      "\n",
      "            </div>\n",
      "            <!--\n",
      "            <div class=\"col-md-12\">\n",
      "                <div class=\"py-4 d-flex justify-content-center align-items-center\">\n",
      "                    <a class=\"mr-4\" href=\"/privacy_terms\">Privacy & terms</a>\n",
      "                </div>\n",
      "            </div>\n",
      "            -->\n",
      "        </div>\n",
      "    </div>\n",
      "</footer>\n",
      "<!-- End of Footer -->\n",
      "\n",
      "<!-- Scripts -->\n",
      "<script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\"></script>\n",
      "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js\" defer></script>\n",
      "<script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js\" defer></script>\n",
      "<script src=\"https://unpkg.com/swiper/swiper-bundle.min.js\"></script>\n",
      "<script>\n",
      "    var swiper = new Swiper('.swiper-container', {\n",
      "        spaceBetween: 20,\n",
      "        loop: true,\n",
      "        navigation: {\n",
      "            nextEl: '.swiper-button-next',\n",
      "            prevEl: '.swiper-button-prev',\n",
      "        },\n",
      "        breakpoints: {\n",
      "            600: {\n",
      "                slidesPerView: 2,\n",
      "                spaceBetween: 10\n",
      "            },\n",
      "            992: {\n",
      "                slidesPerView: 4\n",
      "            }\n",
      "        }\n",
      "    });\n",
      "</script>\n",
      "\n",
      "<!-- Load Bootstrap -->\n",
      "<script>\n",
      "    function loadCSS(href) {\n",
      "        var cssLink = document.createElement(\"link\");\n",
      "        cssLink.rel = \"stylesheet\";\n",
      "        cssLink.href = href;\n",
      "        document.head.appendChild(cssLink);\n",
      "    }\n",
      "    loadCSS(\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\");\n",
      "</script>\n",
      "\n",
      "<!-- Load Font -->\n",
      "<script>\n",
      "    function loadFont() {\n",
      "        var fontLink = document.createElement(\"link\");\n",
      "        fontLink.rel = \"stylesheet\";\n",
      "        fontLink.href = \"https://fonts.googleapis.com/css?family=Rubik\";\n",
      "        document.head.appendChild(fontLink);\n",
      "    }\n",
      "    window.addEventListener(\"load\", loadFont);\n",
      "</script>\n",
      "\n",
      "<!-- Load Screen -->\n",
      "<script>\n",
      "    document.addEventListener('DOMContentLoaded', function () {\n",
      "        // Hide the loading screen\n",
      "        var loadingScreen = document.getElementById('loading-screen');\n",
      "        loadingScreen.style.display = 'none';\n",
      "    });\n",
      "</script>\n",
      "<!-- End of Scripts-->\n",
      "\n",
      "</body>\n",
      "\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# make a get request to the web site\n",
    "url = 'https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B'\n",
    "header = {'User-agent': 'Mozilla/5.0'} # with the user agent, we let Python know for which browser version to retrieve the website\n",
    "web_request = requests.get(url, headers = header)\n",
    "web_request.encoding = web_request.apparent_encoding # set encoding to UTF-8 -- ensuring non-English characters can be read well\n",
    "\n",
    "# return the source code from the request object\n",
    "web_request_source_code = web_request.text\n",
    "\n",
    "# print out the source code to verify you have loaded the correct page\n",
    "print(web_request_source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Why are we using \"user agents\" when making website requests?</b>\n",
    "    <br>\n",
    "\n",
    "- User agents tell a browser which website version to return. For example, your smartphone's browser will request mobile versions of websites, whereas your laptop will request versions suited to larger screens.\n",
    "    \n",
    "- Changing the user agent is also your \"first wall of defense\" when being blocked during data collections. Later, we will learn about other ways to prevent being blocked from automatically extracting information from the web. \n",
    "    \n",
    "- Interested in the ethical aspects of retrieving publicly available web data? Check the relevant sections in [\"Fields of Gold\"](https://journals.sagepub.com/doi/abs/10.1177/00222429221100750?journalCode=jmxa).\n",
    " \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4\n",
    "1. Using the code snippet above, write a function (starting with `def download_website(url):`) that downloads the raw website data for [this artist](https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B), printing it to the screen. Remember to use the same number of spaces or tabs (\"indents\") when writing your function!\n",
    "2. Adapt the function (copy-paste first, relabel as `def save_website(url, filename):`), storing the website's raw code __in a file__ (that you can specify in the second parameter, `filename`). Recall that you can use previously learned concepts, in specific `f=open(<filename>, 'w', encoding='utf-8')`, `f.write()`, and `f.close()`. Rerun the function on the URL above. Does it work?\n",
    "3. Write a loop to store the raw HTML source code for all featured artists on the platform's homepage (listed under \"Featured artists\" at [https://music-to-scrape.org](). Before starting, create an array/list of *dictionaries* (`artists`) with URLs and filenames to store the websites. Use the previously written function `store_website(url, filename`) for this exercise.\n",
    "\n",
    "```\n",
    "artists = [{'url': 'first_url',\n",
    "         'filename': 'filename1.html'},\n",
    "        {'url': 'second_url',\n",
    "         'filename': 'filename2.html'}]\n",
    "```\n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<!-- Head -->\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>We love being scraped | music-to-scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"https://unpkg.com/swiper/swiper-bundle.min.css\" />\n",
      "    <link href=\"https://fonts.googleapis.com/css?family=Rubik\" rel=\"stylesheet\">\n",
      "    <script src=\"https://kit.fontawesome.com/4e7776d591.js\" crossorigin=\"anonymous\"></script>\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/style.css\">\n",
      "    <script src=\"/static/js/cookies.js\"></script>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"cookie-banner\">\n",
      "        <p>This website uses <a href=\"/privacy_terms\">cookies</a> to improve your experience on our website.</p>\n",
      "        <button class=\"btn btn-primary mr-2\" id=\"accept-cookies\">Accept</button>\n",
      "        <button class=\"btn btn-secondary mr-2\" id=\"reject-cookies\">Deny</button>\n",
      "        <button class=\"btn btn-secondary\" id=\"cookie-preferences\" onclick=\"showCookiePreferences()\">Manage Consent</button>\n",
      "    </div>\n",
      "\n",
      "    <div id=\"cookie-preferences-popup\">\n",
      "        <h2>Manage Consent</h2>\n",
      "        <p>You have full control over your cookies at music-to-scrape.org:</p>\n",
      "        <ul>\n",
      "            <li>\n",
      "                <input type=\"checkbox\" id=\"analytics-cookie\">\n",
      "                <label for=\"analytics-cookie\"><strong>Google Analytics:</strong> This code manages the deployment of various marketing and analytics tags on the website.</label>\n",
      "            </li>\n",
      "        </ul>\n",
      "        <p>Want to know more? Check our <a href=\"/privacy_terms\">Privacy & Terms of Use</a></p>\n",
      "        <button class=\"btn btn-primary\" onclick=\"saveCookiePreferences()\">Save Consent</button>\n",
      "    </div>\n",
      "    \n",
      "    \n",
      "\n",
      "<!-- loaded -->\n",
      "\n",
      "<!-- Header -->\n",
      "<header>\n",
      "    <!-- Top Bar -->\n",
      "    <a href=\"about\"><div class=\"top-bar\">\n",
      "\t\t<p>We are a fictitious music streaming service without real data - use us to learn collecting data with web scraping and APIs.</p>\n",
      "\t</div></a>\n",
      "    <!-- End Top Bar -->\n",
      "\n",
      "    <!-- NavBar -->\n",
      "    <nav class=\"navbar navbar-expand-lg navbar-light bg-light\">\n",
      "        <a class=\"navbar-brand\" href=\"/\"><img src=\"/static/images/logo.png\" width=\"200\" height=\"27\" class=\"logo\"></a>\n",
      "        <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#navbarSupportedContent\"\n",
      "            aria-controls=\"navbarSupportedContent\" aria-expanded=\"false\" aria-label=\"Toggle navigation\">\n",
      "            <span class=\"navbar-toggler-icon\"></span>\n",
      "        </button>\n",
      "\n",
      "        <div class=\"collapse navbar-collapse\" id=\"navbarSupportedContent\">\n",
      "            <ul class=\"navbar-nav mr-auto align-content-center\" style=\"color: rgb(1,51,101)\">\n",
      "                <li class=\"nav-item active\" style=\"color: rgb(1,51,101)\">\n",
      "                    <a class=\"nav-link\" href=\"/\">Home <span class=\"sr-only\">(current)</span></a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                    <a class=\"nav-link\" href=\"/tutorial_scraping\">Learn how to scrape</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item\">\n",
      "                    <a class=\"nav-link\" href=\"/tutorial_api\">Learn how to use API</a>\n",
      "                </li>\n",
      "                <li class=\"nav-item dropdown\">\n",
      "                    <a class=\"nav-link dropdown-toggle\" href=\"#\" id=\"navbarDropdown\" role=\"button\"\n",
      "                        data-toggle=\"dropdown\" aria-haspopup=\"true\" aria-expanded=\"false\">\n",
      "                        More Resources\n",
      "                    </a>\n",
      "                    <div class=\"dropdown-menu\" aria-labelledby=\"navbarDropdown\">\n",
      "                        <a class=\"dropdown-item\" href=\"https://api.music-to-scrape.org/docs\">API documentation</a>\n",
      "                        <a class=\"dropdown-item\" href=\"/about\">About us</a>\n",
      "                        <!--<a class=\"dropdown-item\" href=\"#\">Another action</a>\n",
      "                        <div class=\"dropdown-divider\"></div>\n",
      "                        <a class=\"dropdown-item\" href=\"#\">Something else here</a>\n",
      "                        -->\n",
      "                    </div>\n",
      "                </li>\n",
      "            </ul>\n",
      "            <form action=\"/search\" class=\"form-inline my-2 my-lg-0\" method=\"get\">\n",
      "                <input class=\"form-control mr-sm-2\" name=\"query\" type=\"search\" placeholder=\"Search for artists, songs, and users\" aria-label=\"Search\" style=\"width:300px\">\n",
      "                <input type=\"hidden\" name=\"page\" value=\"\">\n",
      "                <button class=\"btn btn-outline-success my-2 my-sm-0\" type=\"submit\">Search</button>\n",
      "            </form>\n",
      "        </div>\n",
      "    </nav>\n",
      "    <!-- End navbar -->\n",
      "</header>\n",
      "\n",
      "\n",
      "\n",
      "<!-- Main Container-->\n",
      "<div class=\"container\">\n",
      "\n",
      "    <!-- Artist Info -->\n",
      "    <section>\n",
      "        <div class=\"row my-3\">\n",
      "            <div class=\"col-lg-4 album_single_img\">\n",
      "                <img src=\"https://images.unsplash.com/photo-1605722243979-fe0be8158232?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8Mnx8fGVufDB8fHx8&w=1000&q=80\"\n",
      "                    class=\"img-fluid\">\n",
      "            </div>\n",
      "            <div class=\"col-lg-8 album_single_text\">\n",
      "                <h2 class=\"artist_info_title\">Russell Malone</h2>\n",
      "                <div class=\"about_artist\">\n",
      "                    <h5>Location:</h5>\n",
      "                    <p>Albany GA</p>\n",
      "                    <h5>Number of plays:</h5>\n",
      "                    <p>10</p>\n",
      "                    <!--<h5>Number of Playlists:</h5>\n",
      "                    <p>24</p>-->\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "    </section>\n",
      "    <!-- End Artist Info -->\n",
      "\n",
      "    <!-- Tracks -->\n",
      "    <section></section>\n",
      "    <div class=\"row my-3\">\n",
      "        <div class=\"col-md-12\">\n",
      "            <h2>Top 10 Songs All Time</h2>\n",
      "            <div class=\"table-responsive\">\n",
      "                <table class=\"table table-striped\">\n",
      "                    <thead>\n",
      "                        <tr>\n",
      "                            <th>#</th>\n",
      "                            <th>Song Title</th>\n",
      "                            <!--<th>Artist</th>-->\n",
      "                            <th>Number of Plays</th>\n",
      "                        </tr>\n",
      "                    </thead>\n",
      "                    <tbody>\n",
      "                        \n",
      "\n",
      "                        <tr onclick=\"window.location.href = 'song?song-id=SOOYYGD12A8C131830';\">\n",
      "                            <td>1</td>\n",
      "                            <td>Sugar Buzz</td>\n",
      "                            <!--<td></td>-->\n",
      "                            <td>10</td>\n",
      "                        </tr>\n",
      "                        \n",
      "                    </tbody>\n",
      "                </table>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    </section>\n",
      "    <!-- End of Tracks-->\n",
      "\n",
      "</div>\n",
      "<!-- End Main Container-->\n",
      "\n",
      "\n",
      "\n",
      "<!-- Footer -->\n",
      "<footer>\n",
      "    <div class=\"container pt-5 border-bottom\">\n",
      "        <div class=\"row\">\n",
      "            <div class=\"col-md-3 col-sm-12 mb-3\">\n",
      "                <img src=\"/static/images/logo.png\" width=\"200\" height=\"30\"\n",
      "                    class=\"logo_footer\"><br><br>\n",
      "                <p>We’re a fictitious music streaming service with a real website and API. Built for educational\n",
      "                    purposes, you can use us to learn web scraping! </p>\n",
      "            </div>\n",
      "            <div class=\"col-md-9 col-sm-12\">\n",
      "                \n",
      "                <div class=\"col-md-4 col-sm-6 col-6 p-0 mb-3 float-left\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">Learn how to scrape</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/tutorial_scraping\">Tutorial: How to scrape\n",
      "                                the site</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/tutorial_api\">Tutorial: Using the\n",
      "                                API</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"https://api.music-to-scrape.org/docs\">API Documentation</a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "\n",
      "                <div class=\"col-md-4 col-sm-6 col-6 p-0 float-left mb-3\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">About us</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/about\">Who we are</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"/privacy_terms\">Privacy & Terms of Use</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a style=\"color: gray;cursor:pointer\" onclick=\"showCookiePreferences()\">Manage Cookies</a></li>\n",
      "                        <!--\n",
      "                            <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\"><a href=\"\">Page 1</a></li>\n",
      "                        -->\n",
      "                    </ul>\n",
      "                </div>\n",
      "                \n",
      "                \n",
      "            \n",
      "                <div class=\"col-md-3 col-sm-6 col-6 mb-3 p-0 float-left\">\n",
      "                    <h5 class=\"mb-4 font-weight-bold text-uppercase\">Connect</h5>\n",
      "                    <ul class=\"list-group\">\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://www.linkedin.com/company/tilburgsciencehub\"><i class=\"fa fa-linkedin mr-1\"></i>\n",
      "                                LinkedIn</a>\n",
      "                        </li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://github.com/tilburgsciencehub/music-to-scrape\" target=\"_blank\"><i class=\"fa fa-github mr-1\"></i>\n",
      "                                GitHub</a>\n",
      "                        </li>\n",
      "                        <li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"https://twitter.com/tilburgscience\" target=\"_blank\"><i class=\"fa fa-twitter mr-1\"></i>Twitter</a>\n",
      "                        </li>\n",
      "                        <!--<li class=\"list-group-item bg-transparent border-0 p-0 mb-2\">\n",
      "                            <a href=\"\" target=\"_blank\"><i class=\"fa fa-youtube mr-1\"></i> YouTube</a>\n",
      "                        </li>\n",
      "                    -->\n",
      "                    </ul>\n",
      "                </div>\n",
      "\n",
      "            </div>\n",
      "            <!--\n",
      "            <div class=\"col-md-12\">\n",
      "                <div class=\"py-4 d-flex justify-content-center align-items-center\">\n",
      "                    <a class=\"mr-4\" href=\"/privacy_terms\">Privacy & terms</a>\n",
      "                </div>\n",
      "            </div>\n",
      "            -->\n",
      "        </div>\n",
      "    </div>\n",
      "</footer>\n",
      "<!-- End of Footer -->\n",
      "\n",
      "<!-- Scripts -->\n",
      "<script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\"></script>\n",
      "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js\" defer></script>\n",
      "<script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js\" defer></script>\n",
      "<script src=\"https://unpkg.com/swiper/swiper-bundle.min.js\"></script>\n",
      "<script>\n",
      "    var swiper = new Swiper('.swiper-container', {\n",
      "        spaceBetween: 20,\n",
      "        loop: true,\n",
      "        navigation: {\n",
      "            nextEl: '.swiper-button-next',\n",
      "            prevEl: '.swiper-button-prev',\n",
      "        },\n",
      "        breakpoints: {\n",
      "            600: {\n",
      "                slidesPerView: 2,\n",
      "                spaceBetween: 10\n",
      "            },\n",
      "            992: {\n",
      "                slidesPerView: 4\n",
      "            }\n",
      "        }\n",
      "    });\n",
      "</script>\n",
      "\n",
      "<!-- Load Bootstrap -->\n",
      "<script>\n",
      "    function loadCSS(href) {\n",
      "        var cssLink = document.createElement(\"link\");\n",
      "        cssLink.rel = \"stylesheet\";\n",
      "        cssLink.href = href;\n",
      "        document.head.appendChild(cssLink);\n",
      "    }\n",
      "    loadCSS(\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\");\n",
      "</script>\n",
      "\n",
      "<!-- Load Font -->\n",
      "<script>\n",
      "    function loadFont() {\n",
      "        var fontLink = document.createElement(\"link\");\n",
      "        fontLink.rel = \"stylesheet\";\n",
      "        fontLink.href = \"https://fonts.googleapis.com/css?family=Rubik\";\n",
      "        document.head.appendChild(fontLink);\n",
      "    }\n",
      "    window.addEventListener(\"load\", loadFont);\n",
      "</script>\n",
      "\n",
      "<!-- Load Screen -->\n",
      "<script>\n",
      "    document.addEventListener('DOMContentLoaded', function () {\n",
      "        // Hide the loading screen\n",
      "        var loadingScreen = document.getElementById('loading-screen');\n",
      "        loadingScreen.style.display = 'none';\n",
      "    });\n",
      "</script>\n",
      "<!-- End of Scripts-->\n",
      "\n",
      "</body>\n",
      "\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Q1\n",
    "import requests\n",
    "\n",
    "def download_website(url):\n",
    "    header = {'User-agent': 'Mozilla/5.0'} # with the user agent, we let Python know for which browser version to retrieve the website\n",
    "    request = requests.get(url, headers = header)\n",
    "    request.encoding = request.apparent_encoding # set encoding to UTF-8\n",
    "    source_code = request.text\n",
    "    print(source_code)\n",
    "\n",
    "download_website('https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done retrieving https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B and saving as website.html\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "import requests\n",
    "\n",
    "def save_website(url, filename):\n",
    "    header = {'User-agent': 'Mozilla/5.0'} # with the user agent, we let Python know for which browser version to retrieve the website\n",
    "    request = requests.get(url, headers = header)\n",
    "    request.encoding = request.apparent_encoding # set encoding to UTF-8\n",
    "    source_code = request.text\n",
    "    f=open(filename, 'w', encoding='utf-8')\n",
    "    f.write(source_code)\n",
    "    f.close()\n",
    "    print(f'Done retrieving {url} and saving as {filename}')\n",
    "\n",
    "save_website('https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B', 'website.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done retrieving https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B and saving as filename1.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARGNGRI11E2835D567 and saving as filename2.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARAVPU21187B993957 and saving as filename3.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARJ66JQ1187B99D2FF and saving as filename4.html\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "artists = [{'url': 'https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B',\n",
    "         'filename': 'filename1.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARGNGRI11E2835D567',\n",
    "         'filename': 'filename2.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARAVPU21187B993957',\n",
    "         'filename': 'filename3.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARJ66JQ1187B99D2FF',\n",
    "         'filename': 'filename4.html'}\n",
    "       ]\n",
    "\n",
    "for artist in artists:\n",
    "    save_website(artist['url'], artist['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.6 Extracting information from a website's source code using `BeautifulSoup` \n",
    "\n",
    "#### Importance\n",
    "\n",
    "It's useful to store raw data from websites (we will make use of this a lot). But &#150; how can extract specific information from a website, such as a product's title or price? \n",
    "\n",
    "Fortunately, we can make use of the *structured* nature of HTML, by selecting information on the basis of:\n",
    " \n",
    "- tags (e.g., `<h1>`, `<table>`),\n",
    "- attributes \n",
    "    - such as IDs (e.g., `<table id=\"example-table\">`), \n",
    "    - class names (e.g., `<table class=\"striped-table\">`), or\n",
    "    - or (generic) attribute-value pairs (e.g., `<table data-gr-ext-installed=\"test\">`).\n",
    "    \n",
    "For now, we'll show you how to apply these concepts using *BeautifulSoup*, a fantastic Python library that allows you to navigate and extract data from HTML files. BeautifulSoup does NOT gather information from the web itself (for this, we still use `requests`, as above). \n",
    "\n",
    "#### Let's try it out\n",
    "First, we import the package `BeautifulSoup` and turn the `web_request_source_code` (the HTML code from the website) into BeautifulSoup object. Once converted, we can easily navigate the code by *tag names*, *attribute names*, or *class names*. This process is called __parsing__, and is one of the central tasks in web scraping.\n",
    "\n",
    "Since we know that the artist name is surrounded by `<h2>` tags (see Google Inspector screenshot above), we use `soup.find('h2')` to parse the name of the artist.\n",
    "\n",
    "Please run the following cells to see things in action!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>Manage Consent</h2>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(web_request_source_code)\n",
    "\n",
    "print(soup.find('h2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.find()` method will always print out the first matching element it finds. In the case of an artist's location, though, all we get when looking for `h5` is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h5>Location:</h5>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...while the location we're interest in is sitting in the \"next\" `p` element:\n",
    "```\n",
    "<h5>Location:</h5>\n",
    "<p>Albany GA</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"jump\" to the next element using the `.findNext()` function. Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Albany GA</p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h5').findNext('p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, right? We can now locate information easily on the site. But... wait a second. Inspecting the site a little closer reveals that the web page has multiple `<h5>` elements, which contain the \"Location\" and \"Number of plays.\" But only the first one will be returned by `.find()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture __all__ matching `<h5>` elements you use the `find_all()` method like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h5>Location:</h5>, <h5>Number of plays:</h5>, <h5 class=\"mb-4 font-weight-bold text-uppercase\">Learn how to scrape</h5>, <h5 class=\"mb-4 font-weight-bold text-uppercase\">About us</h5>, <h5 class=\"mb-4 font-weight-bold text-uppercase\">Connect</h5>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it now returns a list of elements (`[element1, element2]`), so to access individual elements you need to apply indexing (which starts with [0] for the first elements, [1] for the second and so on...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Albany GA</p>\n",
      "<p>10</p>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# obtain first h2 element \n",
    "print(soup.find_all('h5')[0].findNext('p'))\n",
    "\n",
    "# obtain second h2 element\n",
    "print(soup.find_all('h5')[1].findNext('p'))\n",
    "\n",
    "# we can also count the number of elements returned, using the len() function\n",
    "print(len(soup.find_all('h5'))) # will return 5 - as the 'h5' is also used for the styling of other sections of the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both subheaders are still surrounded by `<hp>` and `</p>` tags. To get rid of them, append `.get_text()` to your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albany GA\n"
     ]
    }
   ],
   "source": [
    "# sub header without HTML tags\n",
    "print(soup.find_all('h5')[0].findNext('p').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5\n",
    "\n",
    "1. Retrieve the website's source code, and parse the following information (and print them out):\n",
    "    - artist name\n",
    "    - artist location,\n",
    "    - total number of plays, and\n",
    "    - the number of songs in the \"top 10\" table\n",
    "    \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tips</b>\n",
    "    <br>\n",
    "<ul>\n",
    "    <li>To extract information using <b>class names</b>, use the <code>class_</code> argument in the <code>find()</code> function.<br>\n",
    "        <b>Example:</b> <code>soup.find(class_ = 'class_name_to_find)</code>\n",
    "    </li><br>\n",
    "    <li>Information can also be captured using using <b>attribute-value pairs</b>. Simply use the <code>attrs</code> argument in the <code>find()</code> function.<br>\n",
    "        <b>Example:</b> <code>soup.find(attrs = {'class': 'class_name_to_find'})</code>\n",
    "    </li><br>\n",
    "    <li>Sometimes, you would like to extract the <b>value of a particular attribute</b>. You can do so using the <code>attrs</code> attribute of the <code>find()</code> function.<br>\n",
    "        <b>Example:</b> <code>soup.find(class_ = 'class_name_to_find').attrs['attribute_to_extract']</code>\n",
    "    </li><br>\n",
    "    <li>You can also extract information by <b>counting</b> the number of classes. For example, <code>len(soup.find('h2'))</code> returns the number of <code>h2</code> elements on a site.\n",
    "    </li><br>\n",
    "    <li>\n",
    "        Too much whitespace surrounding your parsed information? Use Python's <code>strip()</code> function, e.g., <code>'   too much whitespace    '.strip()</code>.\n",
    "    </li>\n",
    "</ul>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location:\n",
      "Albany GA\n",
      "10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# number of songs\u001b[39;00m\n\u001b[1;32m      8\u001b[0m song_table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop-songs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43msong_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# artist name\n",
    "print(soup.find('h5').get_text())\n",
    "# location\n",
    "print(soup.find(class_ = 'about_artist').findNext('p').get_text())\n",
    "# plays\n",
    "print(soup.find(class_ = 'about_artist').find_all('h5')[1].findNext('p').get_text())\n",
    "# number of songs\n",
    "song_table = soup.find(class_ = 'top-songs')\n",
    "print(len(song_table.find_all('tr'))-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that it is really important that you build your code from the END to the BEGINNING (think of it like an onion). \n",
    "For example, to arrive at the solution above for the __number of plays__, I would gradually build my code like this - and check, at every iteration, whether my code still runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"about_artist\">\n",
       "<h5>Location:</h5>\n",
       "<p>Albany GA</p>\n",
       "<h5>Number of plays:</h5>\n",
       "<p>10</p>\n",
       "<!--<h5>Number of Playlists:</h5>\n",
       "                    <p>24</p>-->\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt 1: \n",
    "soup.find(class_='about_artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h5>Location:</h5>, <h5>Number of plays:</h5>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt 2: trying to get the second element\n",
    "soup.find(class_='about_artist').find_all('h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5>Number of plays:</h5>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt 3: entering the \"second\" (Python = 1st) element\n",
    "soup.find(class_='about_artist').find_all('h5')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>10</p>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt 4: using the \"find next\" function to get to the next \"p\"\n",
    "soup.find(class_='about_artist').find_all('h5')[1].findNext('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# attempt 5: extracting the text and printing it\n",
    "print(soup.find(class_='about_artist').find_all('h5')[1].findNext('p').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please always adhere to this step-by-step (\"onion-style\") approach to writing code. That way, at each \"attempt\", you can check whether your code still runs. Writing code from scratch (e.g., what I have written above) is impossible for beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Writing your complete first web scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.6__\n",
    "\n",
    "Now it's time to put in action everything we have learnt so far.\n",
    "\n",
    "- Use the list of four URLs specified above to start your data collection,\n",
    "```\n",
    "  artists = [{'url': 'https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B',\n",
    "         'filename': 'filename1.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARGNGRI11E2835D567',\n",
    "         'filename': 'filename2.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARAVPU21187B993957',\n",
    "         'filename': 'filename3.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARJ66JQ1187B99D2FF',\n",
    "         'filename': 'filename4.html'}]\n",
    "       \n",
    "  ```\n",
    "- Write a loop that stores the raw website data in separate HTML files (storing raw data for diagnostic purposes is very helpful!), \n",
    "- Store the extracted information (artist name, location, number of plays, number of songs) in a dictionary, that is stored in new-line separated JSON files.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tips</b>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>\n",
    "    Copy-paste and then modify the <code>store_website()</code> function from above to handle the two tasks of storing AND extracting information (\"parsing\"). </li>\n",
    "            <li>Make use of the <code>return()</code> argument in a function to return the parsed data in a dictionary. </li>\n",
    "        <li>\n",
    "            You can import the json package (<code>import json</code>) and use the <code>json.dumps()</code> function to convert the dictionary to writable output data.\n",
    "        </li>\n",
    " \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done retrieving https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B and saving as filename1.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARGNGRI11E2835D567 and saving as filename2.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARAVPU21187B993957 and saving as filename3.html\n",
      "Done retrieving https://music-to-scrape.org/artist?artist-id=ARJ66JQ1187B99D2FF and saving as filename4.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "artists = [{'url': 'https://music-to-scrape.org/artist?artist-id=AR7KKE01187FB3D87B',\n",
    "         'filename': 'filename1.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARGNGRI11E2835D567',\n",
    "         'filename': 'filename2.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARAVPU21187B993957',\n",
    "         'filename': 'filename3.html'},\n",
    "        {'url': 'https://music-to-scrape.org/artist?artist-id=ARJ66JQ1187B99D2FF',\n",
    "         'filename': 'filename4.html'}]\n",
    "       \n",
    "\n",
    "def parse_website(url, filename):\n",
    "    header = {'User-agent': 'Mozilla/5.0'} \n",
    "    request = requests.get(url, headers = header)\n",
    "    request.encoding = request.apparent_encoding # set encoding to UTF-8\n",
    "    source_code = request.text\n",
    "    f=open(filename, 'w', encoding='utf-8')\n",
    "    f.write(source_code)\n",
    "    f.close()\n",
    "    \n",
    "    # make information \"extractable\" using BeautifulSoup\n",
    "    soup = BeautifulSoup(source_code)\n",
    "    \n",
    "    artist_name = soup.find('h2').get_text()\n",
    "    location = soup.find(class_ = 'about_artist').find_all('p')[0].get_text()\n",
    "    plays = soup.find(class_ = 'about_artist').find_all('p')[1].get_text()\n",
    "    \n",
    "    #song_table = soup.find(class_ = 'top-songs')\n",
    "    #number_of_songs = len(song_table.find_all('tr'))-1\n",
    "\n",
    "    data = {'artist': artist_name,\n",
    "            'location': location,\n",
    "            'plays': int(plays)} # convert plays to a numeric\n",
    "    \n",
    "    print(f'Done retrieving {url} and saving as {filename}')\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "\n",
    "f=open('artist_data.json', 'w', encoding='utf-8')\n",
    "for artist in artists:\n",
    "    data = parse_website(artist['url'], artist['filename'])\n",
    "    f.write(json.dumps(data))\n",
    "    f.write('\\n') # new line to separate objects\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've just learned the first steps in collecting online data from websites! Along with boosting your \"geek\"-factor (wait till you show this to your friends!), you've gained an intuition on how websites are built up (HTML, CSS, JS), how source code translates into a rendered (visual) website (or, in other words, you know how to spoof websites - now, take screenshots and show *that* to your friends...), how websites can be loaded into Python, and how you can use `BeautifulSoup` to extract information using tag or attribute names and classes. Good job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 2. Application Programming Interface (API)\n",
    "\n",
    "\n",
    "### 2.1 What is an API?\n",
    "\n",
    "An equally important data collection method is called Application Programming Interface (API). That's a mouthful, but in essence, it is nothing more than a version of a _website intended for computers, rather than humans, to talk to one another_. \n",
    "\n",
    "APIs are everywhere, and most are used to provide...\n",
    "- data (e.g., retrieve a user name and demographics), \n",
    "- functions (e.g., start playing music from Spotify, turn on your lamps in your \"smart home\"), or \n",
    "- algorithms (e.g., submit an image, retrieve a written text for what's *on* the image).\n",
    "\n",
    "---\n",
    "\n",
    "*Background: Free versus paid APIs*\n",
    "\n",
    "Paid APIs require their users to authenticate themselves. Think of an authentication key as a \"key to unlock the service.\" Web services use such authentication keys to track whether you're allowed to use the API and how much you use it. This offers numerous opportunities for API business models, in which, for example, the service employs a pay-by-request (or by 1,000 requests) model. For example, check how to pay for the API of Chat GPT -- see https://platform.openai.com/docs/introduction.\n",
    "\n",
    "---\n",
    "\n",
    "In what follows, we'll introduce you to the API of [Reddit](https://www.reddit.com), a popular American social news aggregation and discussion site. Reddit gives you an up to date view on what's happening around the world, all sorted through a voting system (\"upvotes\") by 1bn.+ users!\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b><br><br>\n",
    "<ul>\n",
    "    <li>Think of Reddit upvotes as a like on Instagram. Posts are arranged based on the number of votes, and those with many upvotes are featured on the homepage. The grey number next to each post represents the sum of votes (= upvotes - downvotes).\n",
    "    </li>\n",
    "    <li>\n",
    "        Each API relies on slightly different ways to access data. The Reddit API is particularly easy, as it only requires you to append <code>.json</code> to a URL from their website. Most other APIs likely have different ways to map content from their websites to API endpoints. Check the API documentation of your data source for information on this!\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/reddit_homepage.png\" width=60% align=\"left\"  style=\"border: 1px solid black\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 How APIs work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importance__\n",
    "\n",
    "APIs work very similar to websites. At the core, instead of obtaining the source code of a (rendered) web site, you obtain code that computers can easily understand to process the content of a website. APIs provide you with simpler and more scalable ways to obtain data, so you really have to understand how they work.\n",
    "\n",
    "__Let's try it out__\n",
    "\n",
    "Consider the screen shot above (a view of the Reddit website). Here's an example of how the output of the Reddit API (click on it to view it in your browser):\n",
    "\n",
    "https://www.reddit.com/r/science/comments/k0bjqt/study_finds_users_not_notifications_initiate_89.json\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/api_example.png\" width=60% align=\"left\"  style=\"border: 1px solid black\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A few things stand out right away:*\n",
    "\n",
    "- the output only contains text, which is structured according to a data structure (e.g., array or list (`[]`) and dictionary (`{}`)), \n",
    "- there's no human interface with buttons, menus, and links, yet...\n",
    "- you can access it like any other website by filling out the URL in your browser (`reddit.com/r/science/...` in this example).\n",
    "\n",
    "In fact, the API output above corresponds to the (visual) Reddit thread, which you can open here:\n",
    "\n",
    "https://www.reddit.com/r/science/comments/k0bjqt/study_finds_users_not_notifications_initiate_89\n",
    "\n",
    "For example, look at the third and fourth line from above, which states the `title` of the post you can also see below on the rendered website.  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/reddit.png\" width=60% align=\"left\"  style=\"border: 1px solid black\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tips:</b><br>\n",
    "<ul>\n",
    "    <li>If you have taken a look at the API output, you may conclude that making sense of raw JavaScript Object Notation (JSON) is easier said than done. Fortunately, this <a href='https://chrome.google.com/webstore/detail/json-viewer/gbmdgpbipfallnflgajpaliibnhdgobh'>plugin</a> automatically formats and highlights the output such that it's easier to digest. If your browser does not automatically display JSON data in a \"nice\" way, we recommend installing the Chrome plugin. \n",
    "    </li>\n",
    "    <li>\n",
    "After installation, view the output again. That's much better, right?\n",
    "</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1\n",
    "\n",
    "Navigate through the JSON tree structure of the post above and anwer the following questions:\n",
    "\n",
    "1. At the parent level you find two dictionaries at line 5 and 197 (i.e., the blue arrows). Collapse the content and describe in your own words what each dictionary represents. How does it relate to the Reddit HTML page? \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hannesdatta/course-odcm/master/content/docs/modules/week2/webdata-for-dummies/images/reddit_api.gif\" width=70% align=\"left\"  style=\"border: 1px solid black\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The first comment is from the post author (fotogneric) and has gathered the most points. How many downvotes did this comment get (you find the answer in the JSON output)? \n",
    "\n",
    "3. Suppose that you want to extract the date and time each comment was created. What path do you need to navigate? \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tips:</b><br>\n",
    "   <ul> <li>\n",
    "Times are often registered in UTC format, a globally interchangeable time representation (also known as Epoch time). More specifically, it is the number of seconds elapsed since January 1, 1970. It can be used as a universal time scale around the world. \n",
    "    </li>\n",
    "    <li>\n",
    "    Copy-paste the UTC time to an <a href='https://epochconverter.com' target='_blank'>online epoch converter</a> and check whether it corresponds with the date and time on the webpage.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "1. The dictionary that starts at line 5 contains data on the post (title, subreddit, upvote ratio, thumbnail/image, link to article). The other dictionary stores the comments of the post (author, body text, timestamp). \n",
    "2. At the moment of writing this solution (December 2020) the post has 0 downvotes (`'downs': 0`).\n",
    "3. The `created` key stores a large number (e.g., 1606274053) that can be translated into a date and time (for this example: 25 November 2020 03:14 GMT). The corresponding path for the timestamp of the first comment is: `request[1]['data']['children'][0]['data']['created']` (a written description that follows these directions also suffices: first, you take the 2nd element `[1]` in the list, then you choose the `data` key, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Inspect data before collection\n",
    "\n",
    "__Importance__\n",
    "\n",
    "Before we proceed to *downloading* data from an API, it is useful to first inspect the corresponding website (if it exists) to get an understanding for what data is available.\n",
    "\n",
    "Here, we zoom in on \"subreddits\" (which are easier to understand than the comments considered earlier). Subreddits are niche communities centered around a particular topic. Users can nearly post anything in these subreddits, and you'd be surprised to find out what people are talking about. For example, check out the [subreddit on Science](https://www.reddit.com/r/Science).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's try it out__\n",
    "\n",
    "Subreddits all start with `reddit.com/r/...`. Here are a few examples: [askreddit](https://www.reddit.com/r/AskReddit), [aww](https://www.reddit.com/r/aww/), [gifs](https://www.reddit.com/r/gifs/), [showerthoughts](https://www.reddit.com/r/Showerthoughts), [lifehacks](https://www.reddit.com/r/lifehacks), [getmotivated](https://www.reddit.com/r/GetMotivated), [moviedetails](https://www.reddit.com/r/MovieDetails), [todayilearned](https://www.reddit.com/r/todayilearned/), [foodporn](https://www.reddit.com/r/FoodPorn/).\n",
    "\n",
    "Take your time to browse through some of the subreddits, and get familiar with the structure of the pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2\n",
    "Consult the [`marketing`](https://www.reddit.com/r/marketing/hot/) subreddit and answer the following questions: \n",
    "1. For your thesis, you need to collect survey responses. Are you allowed to share a link to your survey in this subreddit? Please explain how you came to this conclusion. \n",
    "2. You post a link (and wonder how many users will potentially be able to see your post). How many users are subscribed to the subreddit? How many users are currently online?\n",
    "3. Like other social media platforms, you can navigate towards Reddit's user profiles and learn more about these persons. Inspect the profile of a user that has posted in the Subreddit. Describe what types of information you can gather from this user. How is the feed organized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "1. No, the subreddit rules prescribe users not to post surveys and homework assignments (right sidebar).\n",
    "2. `r/marketing` is moderated has about 370k members, and (at the time of writing this tutorial), about 160 of them were online.\n",
    "3. On a user page, you find the bio, trophies, communities the user moderates, connected accounts, and most importantly: all user's posts and comments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Retrieving data from the Reddit.com API\n",
    "\n",
    "**Importance**  \n",
    "\n",
    "Many APIs are provided via paid subscriptions, but parts of the Reddit.com API are free to use. To request data from the Reddit API, we need to include `headers` in our HTTP request. Like in web scraping (remember the user agent?), headers contain *meta-data* that are required for the API call to work (e.g., type of browser, language, expected data format, etc.). \n",
    "\n",
    "**Let's try it out**  \n",
    "\n",
    "Below we request the about page of the [`marketing`]() subreddit that includes such a header. We make our first request to the Reddit API and parse the output in the upcoming exercise!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.reddit.com/r/marketing/about/.json'\n",
    "header = {'authority': 'www.reddit.com', 'cache-control': 'max-age=10', 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'sec-fetch-site': 'same-origin', 'sec-fetch-mode': 'navigate', 'sec-fetch-user': '?1', 'sec-fetch-dest': 'document', 'accept-language': 'en-GB,en;q=0.9'}\n",
    "response = requests.get(url, headers=header)\n",
    "json_response = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3\n",
    "1. First, take a look at the `json_response` object. Then, leave out the `headers` parameter in your request (so it becomes `requests.get(url)` instead), rerun the cell, and inspect the `json_response` another time. Are there any differences? \n",
    "2. Write a while-loop that prints the count of the number of currently active users of the `marketing` subreddit. Have your code pause every 5 seconds before refreshing. Stop the loop after 3 iterations. For pausing, use the function `time.sleep(5)`. Import the time package using `import time`.\n",
    "\n",
    "```\n",
    "import time\n",
    "i = 0\n",
    "while i<=3:\n",
    "    print('Starting to collect data, iteration', i+1)\n",
    "    #### YOUR API COLLECTION CODE HERE\n",
    "    print('   waiting 5 seconds...')\n",
    "    time.sleep(5)\n",
    "    i = i + 1\n",
    "\n",
    "```\n",
    "\n",
    "3. Convert your code from the previous exercise into a function `get_usercount()` that takes a `subreddit` as input and returns the total number of users, and the number of currently active users as a dictionary. Test your function for the `science`, `skateboarding`, and `marketing` subreddits. How many total and currently active users do these communities have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "1. Without the `headers` parameter, the API returns an error code (429). Headers are frequently used to track who is using the API. The user of the \"anonymous header\" has pushed the boundaries too much!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "324\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "# Question 2 \n",
    "import time\n",
    "\n",
    "i = 1\n",
    "while i <= 3:\n",
    "    url = 'https://www.reddit.com/r/marketing/about/.json'\n",
    "    header = {'authority': 'www.reddit.com', 'cache-control': 'max-age=10', 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'sec-fetch-site': 'same-origin', 'sec-fetch-mode': 'navigate', 'sec-fetch-user': '?1', 'sec-fetch-dest': 'document', 'accept-language': 'en-GB,en;q=0.9'}\n",
    "    response = requests.get(url, headers=header)\n",
    "    json_response = response.json()\n",
    "    \n",
    "    print(json_response['data']['active_user_count'])\n",
    "    i += 1\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_users\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_user_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 11\u001b[0m \u001b[43mget_usercount\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m, in \u001b[0;36mget_usercount\u001b[0;34m(subreddit)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_usercount\u001b[39m(subreddit):\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.reddit.com/r/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubreddit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/about/.json\u001b[39m\u001b[38;5;124m'\u001b[39m, headers\u001b[38;5;241m=\u001b[39m\u001b[43mheaders\u001b[49m)\n\u001b[1;32m      4\u001b[0m     json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      5\u001b[0m     out \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'headers' is not defined"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "def get_usercount(subreddit):\n",
    "    response = response = requests.get(f'https://www.reddit.com/r/{subreddit}/about/.json', headers=headers)\n",
    "    json_response = response.json()\n",
    "    out = {}\n",
    "    out['subreddit'] = subreddit\n",
    "    out['total_users'] = json_response['data']['subscribers']\n",
    "    out['active_users'] = json_response['data']['active_user_count']\n",
    "    return out\n",
    "    \n",
    "get_usercount('science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_usercount('skateboarding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_usercount('marketing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Retrieving data for multiple subreddits\n",
    "\n",
    "__Importance__\n",
    "\n",
    "Remember the website scraper above? At the end of the scraping exercises, we iterated through a list of books to retrieve data. Here, we do the same for the API `about` endpoint. Iterating through an API endpoint for multiple \"seeds\" (or sampling units) is at the core of each data extraction task. \n",
    "\n",
    "__Try it out__\n",
    "\n",
    "Run the following cell, to see how looping through a set of subreddits works like. Do you see similarities to the scraping example introduced earlier? Exactly: the concept is entirely the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['science', 'skateboarding', 'marketing']\n",
    "\n",
    "for sub in subreddits:\n",
    "    print(get_usercount(sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.4__\n",
    "\n",
    "1. Extend the list of subreddits to at least 10 (by browsing the site and taking some subreddits you're interested in)\n",
    "2. Write a function to return the current timestamp in UNIX/Epoch time and readable time. Append the timestamp information to each retrieved JSON object. Storing the timestamp of retrieval, along with the actual data, will help you to later match the data to other datasets across time.\n",
    "```\n",
    "# retrieving current timestamp (from https://www.geeksforgeeks.org/get-current-timestamp-using-python/)\n",
    "import datetime\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time:\", ct)\n",
    "# ts store timestamp of current time\n",
    "ts = ct.timestamp()\n",
    "print(\"timestamp:\", int(ts))\n",
    "```\n",
    "3. Write a `for` loop through your subreddits, and store all of the retrieved data in a file called `subreddits.json`. When rerunning the code the data may not be overwritten! (so, try running the code a couple of times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solutions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 (added just a few more here...)\n",
    "subreddits = ['science', 'skateboarding', 'marketing', 'music', 'beach']\n",
    "\n",
    "# Q2\n",
    "import datetime\n",
    "\n",
    "def get_time():\n",
    "    # ct stores current time\n",
    "    ct = datetime.datetime.now()\n",
    "    # ts store timestamp of current time\n",
    "    ts = ct.timestamp()\n",
    "    return({'current_time': ct,\n",
    "           'timestamp': ts})\n",
    "\n",
    "get_time()\n",
    "get_time()['timestamp'] # e.g., for only the UNIX timestamp\n",
    "\n",
    "# Q3\n",
    "\n",
    "import json\n",
    "\n",
    "f = open('subreddits.json', 'a', encoding = 'utf-8')\n",
    "\n",
    "for sub in subreddits:\n",
    "    data = get_usercount(sub)\n",
    "    data['retrieval_timestamp'] = int(get_time()['timestamp'])\n",
    "    f.write(json.dumps(data))\n",
    "    f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Wrap up: APIs versus web scrapers\n",
    "\n",
    "Now that you understand what APIs are, you may rightfully wonder: why should I learn APIs when I could scrape the elements from the website instead (like the book webshop)?\n",
    "\n",
    "- One of the major advantages of APIs is that you can directly access the data you need *without all the hassle of selecting the right HTML tags*. \n",
    "\n",
    "- Another advantage is that you can often customize your API request (e.g., the first 100 comments or only posts about science), which may not always be possible in the web interface. \n",
    "\n",
    "- Using APIs is a legit way to get access to website data (mostly, you will have to pay a license fee to use APIs!). So it's a more stable and legit way to retrieve web data compared to web scraping. That's also why we recommend using an API whenever possible. \n",
    "\n",
    "- In practice, though, APIs really can't give you all the data you possibly want, and web scraping allows you to access complementary data (e.g., viewable on a website or somewhere hidden in the source code).\n",
    "\n",
    "More commonalities and differences are also shown in Web Appendix of [\"Fields of Gold\"](https://doi.org/10.1177%2F00222429221100750), Table W1.\n",
    "\n",
    "Happy scraping!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After-class exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Up to now, we have only parsed the information of very few artists (four, to be exact). In this exercise, please try extract the data for a period of about an hour, with pauses of 5 minutes in-between.\n",
    "\n",
    "Use the code written for exercise 1.6 in this tutorial as a starter.\n",
    "\n",
    "Then, append the __timestamp of data collection__ (used in the API part of the webdata for dummies tutorial), and add it to the generated dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have used Jupyter Notebook to execute our code. But, what if you wanted to *schedule and automatically run* your data extraction (e.g., even when you are asleep)?\n",
    "\n",
    "1. Copy your code written in (3) of exercise 2.4 in web data for dummies to a `.py` file, and execute it \n",
    "from the terminal (`python myscript.py`). \n",
    "\n",
    "2. Work through the scheduling tutorial on [Tilburg Science Hub](https://tilburgsciencehub.com/schedule/task/?utm_campaign=referral-short).\n",
    "\n",
    "3. Combine 1 & 2 to automatically schedule the extraction of the API data, every 10 minutes, for a duration of 2 hours\n",
    "\n",
    "4. Open the downloaded `.json` data using the `pandas` package and provide some summary statistics:\n",
    "    \n",
    "    - number of unique subreddits\n",
    "    - number of times each subreddit was scraped\n",
    "    - start and end timestamp of the scraper\n",
    "    - average active users per subreddit\n",
    "\n",
    "```\n",
    "# snippet to load the data into Python\n",
    "import pandas as pd\n",
    "pd.read_json('subreddits.json', lines = True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
