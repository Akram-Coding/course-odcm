oDCM - Opening Lecture 1
========================================================
author: Hannes Datta
date: 
autosize: true

<style>
.small-code pre code {
  font-size: 1em;
}
</style>

<!--#

https://support.rstudio.com/hc/en-us/articles/200486468
-->

```{r setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(reticulate)
py_install("requests")
py_install("bs4")
```

Welcome to oDCM!
========================================================

We're about to start with the first lecture of this class.

- If you're joining on Zoom...
- Please **turn on** your camera; it helps us to interact better!
- The **chat** is open - use it like on Twitch/YouTube to also talk to each other (or to me).
- If you haven't done so, please **explore the course page** at [https://odcm.hannesdatta.com]().

<!--
--- drafted this course for a very long time
- finally got the chance to teaching it now
- what is it about: radical change in the way to work on data-intensive projects
- While you can find tons of resources online on how to scrape, or how to access data from APIs, none of these tutorials will actually teach you how the way you scrape affects your research. This is the void we will.

- happy to share that vision, and share practical tips
-->


Agenda
========================================================

- Getting to know each other
- Motivation for the course
- Course framework and learning goals
- Agenda and practical arrangements

Disclaimer
========================================================
incremental: true

- It's my first live lecture in two years (!)
- Slow me down & use the chat (need a moderator in class!)
- Live streams are *complements*, not substitutes for self-study & course website
- Minimal use of slides; will post
- This is not a class that merely teaches you Python (but, if you invest time, you'll learn Python on the way!)
- Mix of students at various levels (e.g., beginners, advanced Python users)
- I'm a marketer, not a data or computer scientist
- Consider me your coach, not your *distant professor*
- Course is online-first

About myself
========================================================

- born and raised in Germany
- married, 2 kids (3 and 6 years old)
- normally streaming from 'de zolderkamer' in 's-Hertogenbosch
- geek at heart (3D printing, coding), started skateboarding but broke my arm in October (want to get back on the board though)
- Associate Prof at Tilburg University

Key areas of expertise
========================================================

- Substantive interests
  - streaming business models (e.g., music, movies)
  - marketing-mix modeling and optimization

- Methodological interests
  - data management of structured and unstructured data
  - online data collection via APIs and web scraping
  - causal effects with observational data

Teaching activities (all openly available)
========================================================

- MSc Marketing Analytics
    - Data preparation and workflow management (*new*, https://dprep.hannesdatta.com)
    - Online data collection and management (*new*, https://odcm.hannesdatta.com)
    - MSc Thesis supervision (https://thesis.hannesdatta.com)
- Other inititatives
  - Tilburg Science Hub (https://tilburgsciencehub.com)
  - YouTube channel (https://youtube.com/c/hannesdatta)
  - My public code (https://github.com/hannesdatta)
  - More about my work (https://hannesdatta.com)
  

Getting to know you
========================================================
incremental: true

- Passion, talents
- Why are you enrolled in this program?
- Data experience?


Motivation for course 
========================================================

- started out as a PhD student without data
- was interested in music, and found website with data (https://last.fm)
- no best practices in scraping; learnt all by myself and made many mistakes
- scraping undervalued in academic job market, __but__, key role in shaping relevance and rigor of your work
- now scraping and APIs are a large part of what defines me...

Selection of scraping projects I've undertaken
========================================================
incremental: true

- investigate music streaming ([How did music consumption change with Spotify?](https://tiu.nu/spotify))
- [monitored Spotify's user interface and make lists of new releases](https://github.com/hannesdatta/data-spotify-promotions-releases)
- investigate [playlist ecosystem](https://github.com/hannesdatta/data-spotify-playlist-ecosystem) with APIs (tune in to Radio 1 today at 2pm...)
- [scraped reviews at Amazon.com](https://journals.sagepub.com/doi/abs/10.1509/jm.11.0560)
- investigating "video streaming wars" (e.g., Netflix versus Disney+, when do consumers use multiple streaming services?), see [trakt.tv]()
- share code [on GitHub](https://github.com/hannesdatta)
- developed a [methodological framework on scraping/APIs](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3820666) (which we use in this class)
- Faced legal battles...

<!--
- The story about the legal issues you faced (prior to switching to Chartmetric)

- Show example of Chartmetric API output (a website with lots of text)

- Unfortunately, not every websites provides an API
-->

What is scraping, and what are APIs?
========================================================

*With web scraping, you can essentially capture anything you can view in a web browser*

- pricing data at [bol.com](https://bol.com)
- reviews at [Amazon.com](https://amazon.com)
- movie data at [imdb.com](https://imdb.com) or reviews at Rotten Tomatoes

*With APIs, you obtain official data from a firm in a programmatic way*

- e.g., as a developer, interact with Facebook, Instagram, Twitter
- as a researcher, construct data set from analytics firms

Quick web scraper (I)
========================================================
incremental: true
class: small-code

* Let's first import some packages

```{python, eval=TRUE}
import requests
```

* And then call a particular URL (check it out in your browser!)
```{python, eval = TRUE}
url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'
book_request = requests.get(url)
```

* Finally, let's explore the "content" of the page

```{python, eval = TRUE}
print(book_request.text[5710:5900]) 
```


Quick web scraper (II)
========================================================
incremental: true
class: small-code

* Extracted text looked jibberish, so let's "get" only the product title (we use "tags" for this)

```{python, eval = TRUE}
from bs4 import BeautifulSoup
soup = BeautifulSoup(book_request.text)
print(soup.find('h1'))
```

* Or this...
```{python, eval = TRUE}
print(soup.find('h2'))
```

* Works with any website, even anything you see in a browser (e.g., apps)

Quick APIs (I)
========================================================
class: small-code

* APIs are official interfaces by firms for programmers to extract or submit data, or obtain access to an algorithm

* They work *like* websites (i.e., you can call them with the same snippets as before), but usually you need to pay or at least sign up for the service

* ...unless it's about skating, of course ;)

```{python, include=FALSE}
# Let's pretend we're a real user
headers = {'authority': 'www.reddit.com', 'cache-control': 'max-age=0', 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'sec-fetch-site': 'same-origin', 'sec-fetch-mode': 'navigate', 'sec-fetch-user': '?1', 'sec-fetch-dest': 'document', 'accept-language': 'en-GB,en;q=0.9'}
```

```{python, eval = TRUE}
# let's get some data from the skating community
api_request = requests.get('https://www.reddit.com/r/skating/.json', headers=headers)
api_request.text[1:100]
```

Quick (APIs) (II)
==========================================
class: small-code

* or let's structure the output in the JSON format
```{python, eval = TRUE}
api_request.json().get('data').get('children')[0].get('data').get('selftext')
```

Quick APIs (II)
=============================
class: small-code

* we can now "loop" through all of the page's contents

```{python, eval = TRUE}
for item_on_page in api_request.json().get('data').get('children'):
  print(item_on_page.get('data').get('selftext'))
```

* Creepy?! Relax. You'll learn it all.


Opportunities from web scraping
========================================================
incremental: true

- discover/document novel phenomena (e.g., new platforms/technologies)
- boost relevance for managers (e.g., because of using data *they* care about)
- improving methods (e.g., get data to try out new methods, such as review data & text analysis, images, videos)
- improved inferences (i.e., get more accurate results)

Getting inspired...
========================================================

*What are cool websites/services you're currently using a lot?!*

Let's talk about it right now...

Why to care (as a marketer...) (I)
========================================================

![odcm](use_of_webdata.png)

Why to care (as a marketer...) (II)
========================================================

![odcm](citations.png)


Web data versus other marketing data (I)
=============================================

*Why do we need a course on this? Isn't this how research is always done?*

__Yes, but collecting *web data* is different from other datasets!__

- data source selection
  - finding the *right* data source may be difficult as __many__ potential alternatives exist
  - differ in delivery formats (website versus API, compared to CSV/databases)
  - access to data that is *not* available commercially (or that a firm would not like to share)
  
Web data versus other marketing data (II)
=============================================

- extraction design
  - which information to select (which is available?!)
  - type of variables (sales is rare; review scores are abundant)
  - different stakeholders that could potentially be addressed
  - need to tackle legal and ethical issues 
  
Web data versus other marketing data (III)
=============================================

- collection data at scale!
  - unprecedent: it's totally automatic (but prone to errors)
  - need to put *monitoring* procedures in place
  - data is not documented, and there is no direct way to ask questions about the data (sampling?! generalizability?)
  
Each project is totally unique - that's why there is no universal "best way" to approach things...

Methodological Framework
========================================================

![odcm](framework.png)


Learning Goals of this course
========================================================
incremental: true

- Explain how web data has been used in the __academic marketing literature__
-	__Identify web data sources__ and evaluate their value in the context of a specific research question or business problem
- Assess research fit, resource use and mitigate any legal or ethical issues before retrieving data, i.e., __extraction design__
- __Collect data__ via web scraping and Application Protocol Interfaces (APIs) by mixing, extending, and repurposing code snippets
- __Document and archive collected data__ and make it available for public (re)use
- __Track__, evaluate and share your progress on the course's learning goals


Positioning in the study program
========================================================

![odcm](odcm_positioning.png)

Course structure
========================================================

- Weekly modules, structured along the [methodological framework](https://tiu.nu/scraping)
  - Self-study
  - Tutorials
  - Live stream for feedback & immersive activities

- Project in which you put into practice your skills from the weekly modules


Tutorials
========================================================

- Themes
  - Software Installation & Python Bootcamp
  - Webdata for dummies
  - Web scraping 101 & APIs 101 
  - Web scraping & APIs Advanced [optional]
  
- Access
  - run on your own computer (preferred, as you have to run your data collection for a stable experience on your own PC anyways)
  - explore/"try out" in Google Colab! (--> example)

Team project
========================================================

- goals
  - scrape data via web sites or APIs
  - work through the entire method framework
  - receive feedback by students and me (your coach)
  - [project ideas!](https://odcm.hannesdatta.com/docs/course/project/projectideas)

- evaluation
  - specifics are on the [course website](https://odcm.hannesdatta.com/docs/course/project)
  - we'll have a grading rubric (which is already available)
  - self- and peer assessment used

__Please make this a project you can tell friends & family about. Make it matter.__


Course website
========================================================

Visit [https://odcm.hannesdatta.com]()!

- It's open education, __so spread the word!__
- Course website is your #1 resource, Canvas only used for
  - posting important announcements,
  - sign up for teams,
  - submitting data challenges/projects, and
  - discussion board.

- Do all students have access to Canvas?

Common struggles & Tips
========================================================

- Take time to become acquainted with the format (e.g., no Canvas but website & Pulse)
- Can be tough at first, but you will become more experienced rapidly!
-	It may be very difficult to follow DPREP and ODCM simultaneously, but the skills you learn will be very useful for your coming courses, Master Thesis & future career!

<br><br>
-	Some useful tips:
  -	Start preparing early on (the first weeks will be the most challenging!)
  -	Have the same group members across courses
  -	Collaborate with each other and try to help one another!
  
Live streams
========================================================

- use the public chat
- use it like on Twitch or YT (massively)!
- help me as a moderator if I miss questions
- maybe share screen (install Teamviewer via [tilburgsciencehub.com/get/teamviewer]())
- if you have, use two screens (one to code, one to view colleagues/slides)
- recordings posted on Canvas (default); alternative is YouTube

Grading
========================================================

- Team project, with self- and peer assessment (45%)
- (Online) computer exam (50%)
- Tracking learning process (5%)

<!--
::: notes

* Exam: Both multiple choice and open questions (you can't pass this course if you don't learn programming  make sure you actively participate in the team project so that you can replicate it individually)
- more specs on exam later

:::
-->

My commitment
========================================================
incremental: true

- Get up to speed with both web scraping and APIs (and know when to pick which one!)
- Learn a bit of Python, __but__, becoming an expert requires years of practice
- Discuss own work and ideas, __but__ requires interaction, talking to me, working hard
- Open software (usable right away, no admin rights required)
- Bring in your own ideas, don't be afraid to study topics off the main stream!
- I value diversity! Be who you want to be. Say what you want to say.

Brain-dead by coding
========================================================

- Coding can be extremely frustrating if you're starting out
- I tend to become semi-"brain-dead" after a day of coding
- Take breaks! Stop coding. Go for a run. Start again.
- You will learn from your mistakes
- Use cheat sheets and our support section

&#8594; quick feedback loops in first few weeks

<!--
::: notes

Mention how we aim to remedy this initial hurdle? (quick feedback loops especially in the first few weeks)

:::
-->

Steps of escalation & getting in touch
========================================================

When you run into trouble, this is your way out!

1. Try to find the info on the course website (+ updates!)
2. Ask Google and Stackoverflow
3. Ask friend/classmate (form learning groups, e.g., coordinate via discussion board)
4. Can it wait? Defer to live streams.
5. If it can't wait: be in touch with me (--> next slide!)

<!--
::: notes

* Google/Stackoverflow are your best friends
* Live demonstration of how to search on Google and Stackoverflow
* Comment on experiment with live coding sessions (start a call - talk to fellow classmates who're facing the same struggles)


:::
-->

Use of WhatsApp
========================================================

- Please use WhatsApp: +31 13 466 8938.

![WhatsApp](wa_qr.png)

- Let me know youro first names!
- Email is not so optimal


What's in for you?
========================================================

- Essential skills for entrepreneurs
  - e.g., have your own company on the basis of web data and APIs
  - be the linking pin (interface between marketing and analytics)

- Investment in research skills
  - e.g., collect own data & shape its creation to create relevant and rigorous research

- Showcast expertise in coding


Success factors
========================================================

Please tell me __what would make this course a success__ for you

<!--
::: notes

(for me): become more efficient, use Tilburg Science Hub, give me feedback

:::
-->

Getting started
========================================================

- Install software! (this was required preparation before the course started...)

- Do the Python Bootcamp (after all, you need the know the basics!)

- Learn more about the difference between web scraping and APIs (video)

- Work hard...!

- ...and be in touch on WhatsApp for questions/feedback!


__Any questions so far?!__