---
weight: 3
title: "Team Project"
bookCollapseSection: true
description: " "
---

# Team Project

## Goal

Collecting data via web scraping and APIs requires practice. Together with your team members, you plan and execute an online data collection throughout the course, and submit your collected (and documented) data at the end of the course. [Check out our tips for interesting research contexts](projectideas.md).

The focus lies on *completing the complete [workflow for collection online data](../../tutorials/workflow)*. Therefore, keep each stage of your project *manageable* and *feasible*.

## Team composition

- between four to five students per team
- you need to subscribe to a team yourself (be present in the live streams for that; registration on Canvas!)
- we recommend teams to have at least one-two students with coding expertise in Python on their team

## Planning

- Week 1: Seek inspiration for data sources and interesting ideas to conduct academic research or invest into new business opportunities
<!--; the result of that session is a list of project ideas (i.e., with NEW ideas) that students can potentially work on; updates-->
- Week 2: Finalize team compositions, assess data availability and evaluate research fit & resource use
- Weeks 3-5: Build skills (APIs, web scraping), prototype data collection
- Weeks 6-7: Collect your data, and document it for reuse

## Deadline and submission
- 17 October 2021, 6pm
- Please prepare a [data package](grading_details), consisting of
  - the raw data files,
  - the code you used to collect the raw data (i.e., your scraper/API collection script)
  - the documentation,
  - and any source code files required to report statistics/preliminary insights in the documentation.

  ```
  readme.txt <-- your documentation,
                 either in the form of a plain txt file,
                 or a formatted PDF document

  docs\api_documentation.pdf <-- any supporting files
  docs\screenshot.pdf            for the documentation
                                 (e.g., API documentation,
                                 screenshots from the website,
                                 relevant blog articles)

  data\file1.csv <-- your raw data files
  data\file2.csv
  data\file3.csv

  src\collection\collect.py <-- final source code used
                                for collecting the data

  src\reporting\analysis.R <-- final source code used
                       to generate statistics/insights documented
                       in the readme.

  ```
- Submission via [Surf Filesender](https://filesender.surf.nl); send to h.datta@tilburguniversity.edu in one zip file (one email per team).
- Check out the [grading details before starting to work on your project](grading_details).

<!--
- If you are also taking ["Data Preparation and Workflow Management" (dPrep)](https://dprep.hannesdatta.com)...
  - You can use the data collected in this course for the team project in dPrep. The team project in dPrep runs in weeks 6-8, but you definitely need your raw data in week 5 at the latest (to prep well for week 6). In other words: generating some synergies between dPrep and oDCM comes at the cost of working on this project soon enough!
  - Please submit your entire workflow ("the same submissions") for each of the two courses, consisting of
    - your data collection, the raw data, and its documentation (focus of oDCM), and
    - the entire project pipeline (focus of dPrep, consisting of data exploration, data preparation, automation and deployment).
  - For oDCM, please *zip* your entire pipeline (so we're sure to get all the files for grading).
  - For dPrep, please only provide us with the link to your GitHub repository.

-->

<!--
